{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "%cd '/app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading border basis dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# CUDE_VISIBLE_DEVICES=6\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "\n",
    "from pathlib import Path\n",
    "from src.loader.data import load_data\n",
    "from src.loader.data_format.processors.base import ProcessorChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/src/loader/checkpoint.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(os.path.join(checkpoint_path, f'pytorch_model.bin'))\n"
     ]
    }
   ],
   "source": [
    "from src.loader.checkpoint import load_pretrained_bag\n",
    "\n",
    "save_path = 'results/train/expansion/expansion/custom_bart/base_k_lt=5_m=100000'\n",
    "bag = load_pretrained_bag(save_path, from_checkpoint=True)\n",
    "\n",
    "model = bag['model']\n",
    "tokenizer = bag['tokenizer']\n",
    "config = bag['config']\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'C1 E0 E1 E7 [SEP] C1 E1 E4 E3 [SEP] C1 E2 E3 E3 [SEP] C1 E3 E2 E3 [SEP] C1 E4 E1 E3 [SEP] C1 E5 E0 E3 [SEP] C1 E1 E5 E2 [SEP] C1 E2 E4 E2 [SEP] C1 E3 E3 E2 [SEP] C1 E4 E2 E2 [SEP] C1 E5 E1 E2 [SEP] C1 E6 E0 E2 [SEP] C1 E1 E6 E1 [SEP] C1 E2 E5 E1 [SEP] C1 E3 E4 E1 [SEP] C1 E4 E3 E1 [SEP] C1 E5 E2 E1 [SEP] C1 E6 E1 E1 [SEP] C1 E7 E0 E1 [SEP] C1 E2 E6 E0 [SEP] C1 E3 E5 E0 [SEP] C1 E4 E4 E0 [SEP] C1 E5 E3 E0 [SEP] C1 E6 E2 E0 [SEP] C1 E7 E1 E0 [SEP] C1 E8 E0 E0 [SEP] C1 E2 E0 E7 [SEP] C1 E1 E2 E6 [SEP] C1 E2 E1 E6 [SEP] C1 E3 E0 E6 [SEP] C1 E1 E3 E5 [SEP] C1 E2 E2 E5 [SEP] C1 E3 E1 E5 [SEP] C1 E4 E0 E5  [BIGSEP]  C1 E4 E1 E0 + C19 E3 E1 E1 + C27 E4 E0 E0 + C13 E3 E1 E0 + C21 E3 E0 E1  [SEP]  C1 E4 E1 E1 + C19 E3 E1 E2 + C27 E4 E0 E1 + C13 E3 E1 E1 + C21 E3 E0 E2  [SEP]  C1 E4 E2 E0 + C19 E3 E2 E1 + C27 E4 E1 E0 + C13 E3 E2 E0 + C21 E3 E1 E1  [SEP]  C1 E5 E1 E0 + C19 E4 E1 E1 + C27 E5 E0 E0 + C13 E4 E1 E0 + C21 E4 E0 E1  [SEP]  C1 E1 E2 E4 + C25 E0 E3 E4 + C14 E2 E0 E5 + C9 E1 E1 E5 + C1 E0 E2 E5  [SEP]  C1 E2 E1 E4 + C1 E1 E2 E4 + C5 E0 E3 E4 + C3 E2 E0 E5 + C2 E1 E1 E5  [SEP]  C1 E3 E0 E4 + C25 E2 E1 E4 + C14 E1 E2 E4 + C7 E0 E3 E4 + C14 E2 E0 E5  [SEP]  C1 E0 E4 E3 + C15 E3 E0 E4 + C24 E2 E1 E4 + C18 E1 E2 E4 + C15 E0 E3 E4  [SEP]  C1 E1 E3 E3 + C28 E0 E4 E3 + C25 E3 E0 E4 + C4 E2 E1 E4 + C16 E0 E3 E4  [SEP]  C1 E2 E2 E3 + C12 E1 E3 E3 + C25 E0 E4 E3 + C29 E3 E0 E4 + C25 E2 E1 E4  [SEP]  C1 E3 E1 E3 + C18 E2 E2 E3 + C5 E1 E3 E3 + C6 E0 E4 E3 + C18 E3 E0 E4  [SEP]  C1 E4 E0 E3 + C13 E3 E1 E3 + C25 E2 E2 E3 + C30 E1 E3 E3 + C20 E0 E4 E3  [SEP]  C1 E0 E5 E2 + C2 E4 E0 E3 + C6 E3 E1 E3 + C18 E2 E2 E3 + C3 E1 E3 E3  [SEP]  C1 E1 E4 E2 + C13 E0 E5 E2 + C10 E4 E0 E3 + C10 E3 E1 E3 + C28 E2 E2 E3  [SEP]  C1 E2 E3 E2 + C26 E1 E4 E2 + C25 E0 E5 E2 + C6 E4 E0 E3 + C19 E3 E1 E3  [SEP]  C1 E3 E2 E2 + C15 E2 E3 E2 + C8 E1 E4 E2 + C8 E0 E5 E2 + C17 E4 E0 E3  [SEP]  C1 E4 E1 E2 + C19 E3 E1 E3 + C27 E4 E0 E2 + C13 E3 E1 E2 + C21 E3 E0 E3  [SEP]  C1 E5 E0 E2 + C5 E4 E1 E2 + C1 E3 E2 E2 + C29 E2 E3 E2 + C16 E1 E4 E2  [SEP]  C1 E0 E6 E1 + C28 E5 E0 E2 + C23 E4 E1 E2 + C15 E3 E2 E2 + C13 E2 E3 E2  [SEP]  C1 E1 E5 E1 + C29 E5 E0 E2 + C20 E4 E1 E2 + C25 E3 E2 E2 + C14 E2 E3 E2  [SEP]  C1 E2 E4 E1 + C19 E5 E0 E2 + C6 E4 E1 E2 + C8 E3 E2 E2 + C7 E2 E3 E2  [SEP]  C1 E3 E3 E1 + C30 E2 E4 E1 + C8 E1 E5 E1 + C18 E5 E0 E2 + C22 E4 E1 E2  [SEP]  C1 E4 E2 E1 + C19 E3 E2 E2 + C27 E4 E1 E1 + C13 E3 E2 E1 + C21 E3 E1 E2  [SEP]  C1 E5 E1 E1 + C19 E4 E1 E2 + C27 E5 E0 E1 + C13 E4 E1 E1 + C21 E4 E0 E2  [SEP]  C1 E6 E0 E1 + C1 E5 E1 E1 + C5 E4 E2 E1 + C18 E3 E3 E1 + C3 E2 E4 E1  [SEP]  C1 E1 E6 E0 + C25 E6 E0 E1 + C22 E5 E1 E1 + C27 E4 E2 E1 + C14 E3 E3 E1  [SEP]  C1 E2 E5 E0 + C3 E1 E6 E0 + C4 E6 E0 E1 + C27 E5 E1 E1 + C21 E4 E2 E1  [SEP]  C1 E3 E4 E0 + C6 E2 E5 E0 + C25 E6 E0 E1 + C4 E5 E1 E1 + C6 E4 E2 E1  [SEP]  C1 E4 E3 E0 + C19 E3 E3 E1 + C27 E4 E2 E0 + C13 E3 E3 E0 + C21 E3 E2 E1  [SEP]  C1 E5 E2 E0 + C19 E4 E2 E1 + C27 E5 E1 E0 + C13 E4 E2 E0 + C21 E4 E1 E1  [SEP]  C1 E6 E1 E0 + C19 E5 E1 E1 + C27 E6 E0 E0 + C13 E5 E1 E0 + C21 E5 E0 E1  [SEP]  C1 E7 E0 E0 + C3 E6 E1 E0 + C27 E6 E0 E1 + C1 E5 E0 E2 + C9 E3 E0 E4  [SEP]  C1 E0 E1 E7 + C10 E7 E0 E0 + C3 E6 E1 E0 + C18 E5 E2 E0 + C24 E4 E3 E0  [SEP]  C1 E1 E0 E7 + C13 E7 E0 E0 + C15 E6 E1 E0 + C29 E5 E2 E0 + C10 E4 E3 E0  [SEP]  C1 E0 E2 E6 + C5 E1 E0 E7 + C16 E0 E1 E7 + C27 E7 E0 E0 + C6 E6 E1 E0  [SEP]  C1 E1 E1 E6 + C25 E1 E0 E7 + C17 E7 E0 E0 + C5 E6 E1 E0 + C18 E5 E2 E0  [SEP]  C1 E2 E0 E6 + C18 E1 E1 E6 + C11 E0 E2 E6 + C13 E1 E0 E7 + C21 E0 E1 E7  [SEP]  C1 E0 E3 E5 + C7 E2 E0 E6 + C18 E1 E1 E6 + C16 E0 E2 E6 + C22 E1 E0 E7  [SEP]  C1 E1 E2 E5 + C8 E0 E3 E5 + C5 E2 E0 E6 + C16 E1 E1 E6 + C4 E0 E2 E6  [SEP]  C1 E2 E1 E5 + C10 E7 E0 E0 + C27 E6 E1 E0 + C25 E5 E2 E0 + C13 E4 E3 E0  [SEP]  C1 E3 E0 E5 + C9 E2 E1 E5 + C12 E1 E2 E5 + C28 E0 E3 E5 + C8 E2 E0 E6  [SEP]  C1 E1 E3 E4 + C19 E3 E0 E5 + C10 E2 E1 E5 + C29 E1 E2 E5 + C14 E0 E3 E5  [SEP]  C1 E2 E2 E4 + C15 E2 E1 E5 + C5 E7 E0 E0 + C16 E6 E1 E0 + C14 E5 E2 E0  [SEP]  C1 E3 E1 E4 + C30 E7 E0 E0 + C13 E6 E1 E0 + C8 E5 E2 E0 + C10 E4 E3 E0  [SEP]  C1 E4 E0 E4 + C10 E3 E1 E4 + C7 E2 E2 E4 + C15 E3 E0 E5 + C3 E2 E1 E5  [SEP]  C1 E1 E4 E3 + C25 E4 E0 E4 + C4 E3 E1 E4 + C13 E2 E2 E4 + C15 E1 E3 E4  [SEP]  C1 E2 E3 E3 + C2 E4 E0 E4 + C15 E3 E1 E4 + C21 E2 E2 E4 + C13 E3 E0 E5  [SEP]  C1 E3 E2 E3 + C4 E3 E4 E0 + C17 E3 E1 E3 + C11 E6 E0 E0 + C20 E5 E1 E0  [SEP]  C1 E4 E1 E3 + C19 E3 E1 E4 + C27 E4 E0 E3 + C13 E3 E1 E3 + C21 E3 E0 E4  [SEP]  C1 E5 E0 E3 + C17 E4 E1 E3 + C7 E3 E2 E3 + C9 E2 E3 E3 + C20 E4 E0 E4  [SEP]  C1 E1 E5 E2 + C24 E5 E0 E3 + C23 E4 E1 E3 + C8 E3 E2 E3 + C13 E2 E3 E3  [SEP]  C1 E2 E4 E2 + C16 E1 E5 E2 + C22 E5 E0 E3 + C16 E4 E1 E3 + C11 E3 E2 E3  [SEP]  C1 E3 E3 E2 + C21 E4 E1 E3 + C2 E3 E2 E3 + C29 E5 E2 E0 + C9 E4 E3 E0  [SEP]  C1 E4 E2 E2 + C19 E3 E2 E3 + C27 E4 E1 E2 + C13 E3 E2 E2 + C21 E3 E1 E3  [SEP]  C1 E5 E1 E2 + C19 E4 E1 E3 + C27 E5 E0 E2 + C13 E4 E1 E2 + C21 E4 E0 E3  [SEP]  C1 E6 E0 E2 + C28 E5 E1 E2 + C24 E4 E2 E2 + C13 E3 E3 E2 + C27 E5 E0 E3  [SEP]  C1 E1 E6 E1 + C6 E6 E0 E2 + C11 E5 E1 E2 + C6 E4 E2 E2 + C25 E3 E3 E2  [SEP]  C1 E2 E5 E1 + C1 E6 E0 E2 + C2 E5 E1 E2 + C21 E4 E2 E2 + C12 E3 E3 E2  [SEP]  C1 E3 E4 E1 + C15 E6 E0 E2 + C23 E5 E1 E2 + C2 E4 E2 E2 + C10 E3 E3 E2  [SEP]  C1 E4 E3 E1 + C19 E3 E3 E2 + C27 E4 E2 E1 + C13 E3 E3 E1 + C21 E3 E2 E2  [SEP]  C1 E5 E2 E1 + C19 E4 E2 E2 + C27 E5 E1 E1 + C13 E4 E2 E1 + C21 E4 E1 E2  [SEP]  C1 E6 E1 E1 + C19 E5 E1 E2 + C27 E6 E0 E1 + C13 E5 E1 E1 + C21 E5 E0 E2  [SEP]  C1 E7 E0 E1 + C3 E6 E1 E1 + C27 E6 E0 E2 + C1 E5 E0 E3 + C9 E3 E0 E5  [SEP]  C1 E2 E6 E0 + C3 E7 E0 E1 + C30 E6 E1 E1 + C24 E5 E2 E1 + C4 E4 E3 E1  [SEP]  C1 E3 E5 E0 + C22 E6 E1 E1 + C16 E5 E2 E1 + C3 E4 E3 E1 + C13 E3 E4 E1  [SEP]  C1 E4 E4 E0 + C19 E3 E4 E1 + C27 E4 E3 E0 + C13 E3 E4 E0 + C21 E3 E3 E1  [SEP]  C1 E5 E3 E0 + C2 E5 E2 E1 + C4 E5 E1 E2 + C18 E5 E2 E0 + C7 E4 E3 E0  [SEP]  C1 E6 E2 E0 + C19 E5 E2 E1 + C27 E6 E1 E0 + C13 E5 E2 E0 + C21 E5 E1 E1  [SEP]  C1 E7 E1 E0 + C19 E6 E1 E1 + C27 E7 E0 E0 + C13 E6 E1 E0 + C21 E6 E0 E1  [SEP]  C1 E8 E0 E0 + C3 E7 E1 E0 + C27 E7 E0 E1 + C1 E6 E0 E2 + C9 E4 E0 E4  [SEP]  C1 E2 E0 E7 + C21 E8 E0 E0 + C2 E7 E1 E0 + C6 E6 E2 E0 + C27 E5 E3 E0  [SEP]  C1 E1 E2 E6 + C20 E2 E0 E7 + C20 E8 E0 E0 + C8 E7 E1 E0 + C4 E6 E2 E0  [SEP]  C1 E2 E1 E6 + C14 E2 E0 E7 + C23 E8 E0 E0 + C17 E7 E1 E0 + C25 E6 E2 E0  [SEP]  C1 E3 E0 E6 + C11 E2 E1 E6 + C19 E1 E2 E6 + C15 E2 E0 E7 + C23 E8 E0 E0  [SEP]  C1 E1 E3 E5 + C6 E2 E1 E6 + C30 E2 E0 E7 + C13 E8 E0 E0 + C5 E7 E1 E0  [SEP]  C1 E2 E2 E5 + C15 E2 E1 E6 + C5 E7 E0 E1 + C16 E6 E1 E1 + C14 E5 E2 E1  [SEP]  C1 E3 E1 E5 + C21 E8 E0 E0 + C28 E7 E1 E0 + C29 E6 E2 E0 + C16 E5 E3 E0  [SEP]  C1 E4 E0 E5 + C10 E3 E1 E5 + C7 E2 E2 E5 + C15 E3 E0 E6 + C3 E2 E1 E6',\n",
       " 'target': 'C1 E1 E0 E0 [SEP] C1 E1 E2 E4 [SEP] C1 E1 E0 E0 [SEP] C1 E2 E1 E4 [SEP] C1 E0 E0 E1 [SEP] C1 E2 E1 E4 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E0 E4 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E0 E4 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E0 E4 [SEP] C1 E1 E0 E0 [SEP] C1 E0 E4 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E0 E4 E3 [SEP] C1 E1 E0 E0 [SEP] C1 E1 E3 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E1 E3 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E1 E3 E3 [SEP] C1 E1 E0 E0 [SEP] C1 E2 E2 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E2 E2 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E2 E2 E3 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E1 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E1 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E1 E3 [SEP] C1 E1 E0 E0 [SEP] C1 E4 E0 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E4 E0 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E4 E0 E3 [SEP] C1 E1 E0 E0 [SEP] C1 E0 E5 E2 [SEP] C1 E0 E0 E1 [SEP] C1 E0 E5 E2 [SEP] C1 E1 E0 E0 [SEP] C1 E1 E4 E2 [SEP] C1 E0 E1 E0 [SEP] C1 E1 E4 E2',\n",
       " 'input_monomial_ids': [[0, 0, 0, 0, 2],\n",
       "  [0, 0, 1, 7, 0],\n",
       "  [0, 1, 4, 3, 0],\n",
       "  [0, 2, 3, 3, 0],\n",
       "  [0, 3, 2, 3, 0],\n",
       "  [0, 4, 1, 3, 0],\n",
       "  [0, 5, 0, 3, 0],\n",
       "  [0, 1, 5, 2, 0],\n",
       "  [0, 2, 4, 2, 0],\n",
       "  [0, 3, 3, 2, 0],\n",
       "  [0, 4, 2, 2, 0],\n",
       "  [0, 5, 1, 2, 0],\n",
       "  [0, 6, 0, 2, 0],\n",
       "  [0, 1, 6, 1, 0],\n",
       "  [0, 2, 5, 1, 0],\n",
       "  [0, 3, 4, 1, 0],\n",
       "  [0, 4, 3, 1, 0],\n",
       "  [0, 5, 2, 1, 0],\n",
       "  [0, 6, 1, 1, 0],\n",
       "  [0, 7, 0, 1, 0],\n",
       "  [0, 2, 6, 0, 0],\n",
       "  [0, 3, 5, 0, 0],\n",
       "  [0, 4, 4, 0, 0],\n",
       "  [0, 5, 3, 0, 0],\n",
       "  [0, 6, 2, 0, 0],\n",
       "  [0, 7, 1, 0, 0],\n",
       "  [0, 8, 0, 0, 0],\n",
       "  [0, 2, 0, 7, 0],\n",
       "  [0, 1, 2, 6, 0],\n",
       "  [0, 2, 1, 6, 0],\n",
       "  [0, 3, 0, 6, 0],\n",
       "  [0, 1, 3, 5, 0],\n",
       "  [0, 2, 2, 5, 0],\n",
       "  [0, 3, 1, 5, 0],\n",
       "  [0, 4, 0, 5, 5],\n",
       "  [0, 4, 1, 0, 4],\n",
       "  [18, 3, 1, 1, 4],\n",
       "  [26, 4, 0, 0, 4],\n",
       "  [12, 3, 1, 0, 4],\n",
       "  [20, 3, 0, 1, 0],\n",
       "  [0, 4, 1, 1, 4],\n",
       "  [18, 3, 1, 2, 4],\n",
       "  [26, 4, 0, 1, 4],\n",
       "  [12, 3, 1, 1, 4],\n",
       "  [20, 3, 0, 2, 0],\n",
       "  [0, 4, 2, 0, 4],\n",
       "  [18, 3, 2, 1, 4],\n",
       "  [26, 4, 1, 0, 4],\n",
       "  [12, 3, 2, 0, 4],\n",
       "  [20, 3, 1, 1, 0],\n",
       "  [0, 5, 1, 0, 4],\n",
       "  [18, 4, 1, 1, 4],\n",
       "  [26, 5, 0, 0, 4],\n",
       "  [12, 4, 1, 0, 4],\n",
       "  [20, 4, 0, 1, 0],\n",
       "  [0, 1, 2, 4, 4],\n",
       "  [24, 0, 3, 4, 4],\n",
       "  [13, 2, 0, 5, 4],\n",
       "  [8, 1, 1, 5, 4],\n",
       "  [0, 0, 2, 5, 0],\n",
       "  [0, 2, 1, 4, 4],\n",
       "  [0, 1, 2, 4, 4],\n",
       "  [4, 0, 3, 4, 4],\n",
       "  [2, 2, 0, 5, 4],\n",
       "  [1, 1, 1, 5, 0],\n",
       "  [0, 3, 0, 4, 4],\n",
       "  [24, 2, 1, 4, 4],\n",
       "  [13, 1, 2, 4, 4],\n",
       "  [6, 0, 3, 4, 4],\n",
       "  [13, 2, 0, 5, 0],\n",
       "  [0, 0, 4, 3, 4],\n",
       "  [14, 3, 0, 4, 4],\n",
       "  [23, 2, 1, 4, 4],\n",
       "  [17, 1, 2, 4, 4],\n",
       "  [14, 0, 3, 4, 0],\n",
       "  [0, 1, 3, 3, 4],\n",
       "  [27, 0, 4, 3, 4],\n",
       "  [24, 3, 0, 4, 4],\n",
       "  [3, 2, 1, 4, 4],\n",
       "  [15, 0, 3, 4, 0],\n",
       "  [0, 2, 2, 3, 4],\n",
       "  [11, 1, 3, 3, 4],\n",
       "  [24, 0, 4, 3, 4],\n",
       "  [28, 3, 0, 4, 4],\n",
       "  [24, 2, 1, 4, 0],\n",
       "  [0, 3, 1, 3, 4],\n",
       "  [17, 2, 2, 3, 4],\n",
       "  [4, 1, 3, 3, 4],\n",
       "  [5, 0, 4, 3, 4],\n",
       "  [17, 3, 0, 4, 0],\n",
       "  [0, 4, 0, 3, 4],\n",
       "  [12, 3, 1, 3, 4],\n",
       "  [24, 2, 2, 3, 4],\n",
       "  [29, 1, 3, 3, 4],\n",
       "  [19, 0, 4, 3, 0],\n",
       "  [0, 0, 5, 2, 4],\n",
       "  [1, 4, 0, 3, 4],\n",
       "  [5, 3, 1, 3, 4],\n",
       "  [17, 2, 2, 3, 4],\n",
       "  [2, 1, 3, 3, 0],\n",
       "  [0, 1, 4, 2, 4],\n",
       "  [12, 0, 5, 2, 4],\n",
       "  [9, 4, 0, 3, 4],\n",
       "  [9, 3, 1, 3, 4],\n",
       "  [27, 2, 2, 3, 0],\n",
       "  [0, 2, 3, 2, 4],\n",
       "  [25, 1, 4, 2, 4],\n",
       "  [24, 0, 5, 2, 4],\n",
       "  [5, 4, 0, 3, 4],\n",
       "  [18, 3, 1, 3, 0],\n",
       "  [0, 3, 2, 2, 4],\n",
       "  [14, 2, 3, 2, 4],\n",
       "  [7, 1, 4, 2, 4],\n",
       "  [7, 0, 5, 2, 4],\n",
       "  [16, 4, 0, 3, 0],\n",
       "  [0, 4, 1, 2, 4],\n",
       "  [18, 3, 1, 3, 4],\n",
       "  [26, 4, 0, 2, 4],\n",
       "  [12, 3, 1, 2, 4],\n",
       "  [20, 3, 0, 3, 0],\n",
       "  [0, 5, 0, 2, 4],\n",
       "  [4, 4, 1, 2, 4],\n",
       "  [0, 3, 2, 2, 4],\n",
       "  [28, 2, 3, 2, 4],\n",
       "  [15, 1, 4, 2, 0],\n",
       "  [0, 0, 6, 1, 4],\n",
       "  [27, 5, 0, 2, 4],\n",
       "  [22, 4, 1, 2, 4],\n",
       "  [14, 3, 2, 2, 4],\n",
       "  [12, 2, 3, 2, 0],\n",
       "  [0, 1, 5, 1, 4],\n",
       "  [28, 5, 0, 2, 4],\n",
       "  [19, 4, 1, 2, 4],\n",
       "  [24, 3, 2, 2, 4],\n",
       "  [13, 2, 3, 2, 0],\n",
       "  [0, 2, 4, 1, 4],\n",
       "  [18, 5, 0, 2, 4],\n",
       "  [5, 4, 1, 2, 4],\n",
       "  [7, 3, 2, 2, 4],\n",
       "  [6, 2, 3, 2, 0],\n",
       "  [0, 3, 3, 1, 4],\n",
       "  [29, 2, 4, 1, 4],\n",
       "  [7, 1, 5, 1, 4],\n",
       "  [17, 5, 0, 2, 4],\n",
       "  [21, 4, 1, 2, 0],\n",
       "  [0, 4, 2, 1, 4],\n",
       "  [18, 3, 2, 2, 4],\n",
       "  [26, 4, 1, 1, 4],\n",
       "  [12, 3, 2, 1, 4],\n",
       "  [20, 3, 1, 2, 0],\n",
       "  [0, 5, 1, 1, 4],\n",
       "  [18, 4, 1, 2, 4],\n",
       "  [26, 5, 0, 1, 4],\n",
       "  [12, 4, 1, 1, 4],\n",
       "  [20, 4, 0, 2, 0],\n",
       "  [0, 6, 0, 1, 4],\n",
       "  [0, 5, 1, 1, 4],\n",
       "  [4, 4, 2, 1, 4],\n",
       "  [17, 3, 3, 1, 4],\n",
       "  [2, 2, 4, 1, 0],\n",
       "  [0, 1, 6, 0, 4],\n",
       "  [24, 6, 0, 1, 4],\n",
       "  [21, 5, 1, 1, 4],\n",
       "  [26, 4, 2, 1, 4],\n",
       "  [13, 3, 3, 1, 0],\n",
       "  [0, 2, 5, 0, 4],\n",
       "  [2, 1, 6, 0, 4],\n",
       "  [3, 6, 0, 1, 4],\n",
       "  [26, 5, 1, 1, 4],\n",
       "  [20, 4, 2, 1, 0],\n",
       "  [0, 3, 4, 0, 4],\n",
       "  [5, 2, 5, 0, 4],\n",
       "  [24, 6, 0, 1, 4],\n",
       "  [3, 5, 1, 1, 4],\n",
       "  [5, 4, 2, 1, 0],\n",
       "  [0, 4, 3, 0, 4],\n",
       "  [18, 3, 3, 1, 4],\n",
       "  [26, 4, 2, 0, 4],\n",
       "  [12, 3, 3, 0, 4],\n",
       "  [20, 3, 2, 1, 0],\n",
       "  [0, 5, 2, 0, 4],\n",
       "  [18, 4, 2, 1, 4],\n",
       "  [26, 5, 1, 0, 4],\n",
       "  [12, 4, 2, 0, 4],\n",
       "  [20, 4, 1, 1, 0],\n",
       "  [0, 6, 1, 0, 4],\n",
       "  [18, 5, 1, 1, 4],\n",
       "  [26, 6, 0, 0, 4],\n",
       "  [12, 5, 1, 0, 4],\n",
       "  [20, 5, 0, 1, 0],\n",
       "  [0, 7, 0, 0, 4],\n",
       "  [2, 6, 1, 0, 4],\n",
       "  [26, 6, 0, 1, 4],\n",
       "  [0, 5, 0, 2, 4],\n",
       "  [8, 3, 0, 4, 0],\n",
       "  [0, 0, 1, 7, 4],\n",
       "  [9, 7, 0, 0, 4],\n",
       "  [2, 6, 1, 0, 4],\n",
       "  [17, 5, 2, 0, 4],\n",
       "  [23, 4, 3, 0, 0],\n",
       "  [0, 1, 0, 7, 4],\n",
       "  [12, 7, 0, 0, 4],\n",
       "  [14, 6, 1, 0, 4],\n",
       "  [28, 5, 2, 0, 4],\n",
       "  [9, 4, 3, 0, 0],\n",
       "  [0, 0, 2, 6, 4],\n",
       "  [4, 1, 0, 7, 4],\n",
       "  [15, 0, 1, 7, 4],\n",
       "  [26, 7, 0, 0, 4],\n",
       "  [5, 6, 1, 0, 0],\n",
       "  [0, 1, 1, 6, 4],\n",
       "  [24, 1, 0, 7, 4],\n",
       "  [16, 7, 0, 0, 4],\n",
       "  [4, 6, 1, 0, 4],\n",
       "  [17, 5, 2, 0, 0],\n",
       "  [0, 2, 0, 6, 4],\n",
       "  [17, 1, 1, 6, 4],\n",
       "  [10, 0, 2, 6, 4],\n",
       "  [12, 1, 0, 7, 4],\n",
       "  [20, 0, 1, 7, 0],\n",
       "  [0, 0, 3, 5, 4],\n",
       "  [6, 2, 0, 6, 4],\n",
       "  [17, 1, 1, 6, 4],\n",
       "  [15, 0, 2, 6, 4],\n",
       "  [21, 1, 0, 7, 0],\n",
       "  [0, 1, 2, 5, 4],\n",
       "  [7, 0, 3, 5, 4],\n",
       "  [4, 2, 0, 6, 4],\n",
       "  [15, 1, 1, 6, 4],\n",
       "  [3, 0, 2, 6, 0],\n",
       "  [0, 2, 1, 5, 4],\n",
       "  [9, 7, 0, 0, 4],\n",
       "  [26, 6, 1, 0, 4],\n",
       "  [24, 5, 2, 0, 4],\n",
       "  [12, 4, 3, 0, 0],\n",
       "  [0, 3, 0, 5, 4],\n",
       "  [8, 2, 1, 5, 4],\n",
       "  [11, 1, 2, 5, 4],\n",
       "  [27, 0, 3, 5, 4],\n",
       "  [7, 2, 0, 6, 0],\n",
       "  [0, 1, 3, 4, 4],\n",
       "  [18, 3, 0, 5, 4],\n",
       "  [9, 2, 1, 5, 4],\n",
       "  [28, 1, 2, 5, 4],\n",
       "  [13, 0, 3, 5, 0],\n",
       "  [0, 2, 2, 4, 4],\n",
       "  [14, 2, 1, 5, 4],\n",
       "  [4, 7, 0, 0, 4],\n",
       "  [15, 6, 1, 0, 4],\n",
       "  [13, 5, 2, 0, 0],\n",
       "  [0, 3, 1, 4, 4],\n",
       "  [29, 7, 0, 0, 4],\n",
       "  [12, 6, 1, 0, 4],\n",
       "  [7, 5, 2, 0, 4],\n",
       "  [9, 4, 3, 0, 0],\n",
       "  [0, 4, 0, 4, 4],\n",
       "  [9, 3, 1, 4, 4],\n",
       "  [6, 2, 2, 4, 4],\n",
       "  [14, 3, 0, 5, 4],\n",
       "  [2, 2, 1, 5, 0],\n",
       "  [0, 1, 4, 3, 4],\n",
       "  [24, 4, 0, 4, 4],\n",
       "  [3, 3, 1, 4, 4],\n",
       "  [12, 2, 2, 4, 4],\n",
       "  [14, 1, 3, 4, 0],\n",
       "  [0, 2, 3, 3, 4],\n",
       "  [1, 4, 0, 4, 4],\n",
       "  [14, 3, 1, 4, 4],\n",
       "  [20, 2, 2, 4, 4],\n",
       "  [12, 3, 0, 5, 0],\n",
       "  [0, 3, 2, 3, 4],\n",
       "  [3, 3, 4, 0, 4],\n",
       "  [16, 3, 1, 3, 4],\n",
       "  [10, 6, 0, 0, 4],\n",
       "  [19, 5, 1, 0, 0],\n",
       "  [0, 4, 1, 3, 4],\n",
       "  [18, 3, 1, 4, 4],\n",
       "  [26, 4, 0, 3, 4],\n",
       "  [12, 3, 1, 3, 4],\n",
       "  [20, 3, 0, 4, 0],\n",
       "  [0, 5, 0, 3, 4],\n",
       "  [16, 4, 1, 3, 4],\n",
       "  [6, 3, 2, 3, 4],\n",
       "  [8, 2, 3, 3, 4],\n",
       "  [19, 4, 0, 4, 0],\n",
       "  [0, 1, 5, 2, 4],\n",
       "  [23, 5, 0, 3, 4],\n",
       "  [22, 4, 1, 3, 4],\n",
       "  [7, 3, 2, 3, 4],\n",
       "  [12, 2, 3, 3, 0],\n",
       "  [0, 2, 4, 2, 4],\n",
       "  [15, 1, 5, 2, 4],\n",
       "  [21, 5, 0, 3, 4],\n",
       "  [15, 4, 1, 3, 4],\n",
       "  [10, 3, 2, 3, 0],\n",
       "  [0, 3, 3, 2, 4],\n",
       "  [20, 4, 1, 3, 4],\n",
       "  [1, 3, 2, 3, 4],\n",
       "  [28, 5, 2, 0, 4],\n",
       "  [8, 4, 3, 0, 0],\n",
       "  [0, 4, 2, 2, 4],\n",
       "  [18, 3, 2, 3, 4],\n",
       "  [26, 4, 1, 2, 4],\n",
       "  [12, 3, 2, 2, 4],\n",
       "  [20, 3, 1, 3, 0],\n",
       "  [0, 5, 1, 2, 4],\n",
       "  [18, 4, 1, 3, 4],\n",
       "  [26, 5, 0, 2, 4],\n",
       "  [12, 4, 1, 2, 4],\n",
       "  [20, 4, 0, 3, 0],\n",
       "  [0, 6, 0, 2, 4],\n",
       "  [27, 5, 1, 2, 4],\n",
       "  [23, 4, 2, 2, 4],\n",
       "  [12, 3, 3, 2, 4],\n",
       "  [26, 5, 0, 3, 0],\n",
       "  [0, 1, 6, 1, 4],\n",
       "  [5, 6, 0, 2, 4],\n",
       "  [10, 5, 1, 2, 4],\n",
       "  [5, 4, 2, 2, 4],\n",
       "  [24, 3, 3, 2, 0],\n",
       "  [0, 2, 5, 1, 4],\n",
       "  [0, 6, 0, 2, 4],\n",
       "  [1, 5, 1, 2, 4],\n",
       "  [20, 4, 2, 2, 4],\n",
       "  [11, 3, 3, 2, 0],\n",
       "  [0, 3, 4, 1, 4],\n",
       "  [14, 6, 0, 2, 4],\n",
       "  [22, 5, 1, 2, 4],\n",
       "  [1, 4, 2, 2, 4],\n",
       "  [9, 3, 3, 2, 0],\n",
       "  [0, 4, 3, 1, 4],\n",
       "  [18, 3, 3, 2, 4],\n",
       "  [26, 4, 2, 1, 4],\n",
       "  [12, 3, 3, 1, 4],\n",
       "  [20, 3, 2, 2, 0],\n",
       "  [0, 5, 2, 1, 4],\n",
       "  [18, 4, 2, 2, 4],\n",
       "  [26, 5, 1, 1, 4],\n",
       "  [12, 4, 2, 1, 4],\n",
       "  [20, 4, 1, 2, 0],\n",
       "  [0, 6, 1, 1, 4],\n",
       "  [18, 5, 1, 2, 4],\n",
       "  [26, 6, 0, 1, 4],\n",
       "  [12, 5, 1, 1, 4],\n",
       "  [20, 5, 0, 2, 0],\n",
       "  [0, 7, 0, 1, 4],\n",
       "  [2, 6, 1, 1, 4],\n",
       "  [26, 6, 0, 2, 4],\n",
       "  [0, 5, 0, 3, 4],\n",
       "  [8, 3, 0, 5, 0],\n",
       "  [0, 2, 6, 0, 4],\n",
       "  [2, 7, 0, 1, 4],\n",
       "  [29, 6, 1, 1, 4],\n",
       "  [23, 5, 2, 1, 4],\n",
       "  [3, 4, 3, 1, 0],\n",
       "  [0, 3, 5, 0, 4],\n",
       "  [21, 6, 1, 1, 4],\n",
       "  [15, 5, 2, 1, 4],\n",
       "  [2, 4, 3, 1, 4],\n",
       "  [12, 3, 4, 1, 0],\n",
       "  [0, 4, 4, 0, 4],\n",
       "  [18, 3, 4, 1, 4],\n",
       "  [26, 4, 3, 0, 4],\n",
       "  [12, 3, 4, 0, 4],\n",
       "  [20, 3, 3, 1, 0],\n",
       "  [0, 5, 3, 0, 4],\n",
       "  [1, 5, 2, 1, 4],\n",
       "  [3, 5, 1, 2, 4],\n",
       "  [17, 5, 2, 0, 4],\n",
       "  [6, 4, 3, 0, 0],\n",
       "  [0, 6, 2, 0, 4],\n",
       "  [18, 5, 2, 1, 4],\n",
       "  [26, 6, 1, 0, 4],\n",
       "  [12, 5, 2, 0, 4],\n",
       "  [20, 5, 1, 1, 0],\n",
       "  [0, 7, 1, 0, 4],\n",
       "  [18, 6, 1, 1, 4],\n",
       "  [26, 7, 0, 0, 4],\n",
       "  [12, 6, 1, 0, 4],\n",
       "  [20, 6, 0, 1, 0],\n",
       "  [0, 8, 0, 0, 4],\n",
       "  [2, 7, 1, 0, 4],\n",
       "  [26, 7, 0, 1, 4],\n",
       "  [0, 6, 0, 2, 4],\n",
       "  [8, 4, 0, 4, 0],\n",
       "  [0, 2, 0, 7, 4],\n",
       "  [20, 8, 0, 0, 4],\n",
       "  [1, 7, 1, 0, 4],\n",
       "  [5, 6, 2, 0, 4],\n",
       "  [26, 5, 3, 0, 0],\n",
       "  [0, 1, 2, 6, 4],\n",
       "  [19, 2, 0, 7, 4],\n",
       "  [19, 8, 0, 0, 4],\n",
       "  [7, 7, 1, 0, 4],\n",
       "  [3, 6, 2, 0, 0],\n",
       "  [0, 2, 1, 6, 4],\n",
       "  [13, 2, 0, 7, 4],\n",
       "  [22, 8, 0, 0, 4],\n",
       "  [16, 7, 1, 0, 4],\n",
       "  [24, 6, 2, 0, 0],\n",
       "  [0, 3, 0, 6, 4],\n",
       "  [10, 2, 1, 6, 4],\n",
       "  [18, 1, 2, 6, 4],\n",
       "  [14, 2, 0, 7, 4],\n",
       "  [22, 8, 0, 0, 0],\n",
       "  [0, 1, 3, 5, 4],\n",
       "  [5, 2, 1, 6, 4],\n",
       "  [29, 2, 0, 7, 4],\n",
       "  [12, 8, 0, 0, 4],\n",
       "  [4, 7, 1, 0, 0],\n",
       "  [0, 2, 2, 5, 4],\n",
       "  [14, 2, 1, 6, 4],\n",
       "  [4, 7, 0, 1, 4],\n",
       "  [15, 6, 1, 1, 4],\n",
       "  [13, 5, 2, 1, 0],\n",
       "  [0, 3, 1, 5, 4],\n",
       "  [20, 8, 0, 0, 4],\n",
       "  [27, 7, 1, 0, 4],\n",
       "  [28, 6, 2, 0, 4],\n",
       "  [15, 5, 3, 0, 0],\n",
       "  [0, 4, 0, 5, 4],\n",
       "  [9, 3, 1, 5, 4],\n",
       "  [6, 2, 2, 5, 4],\n",
       "  [14, 3, 0, 6, 4],\n",
       "  [2, 2, 1, 6, 3]],\n",
       " 'target_monomial_ids': [[0, 0, 0, 0, 2],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 1, 2, 4, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 2, 1, 4, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 2, 1, 4, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 3, 0, 4, 0],\n",
       "  [0, 0, 1, 0, 0],\n",
       "  [0, 3, 0, 4, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 3, 0, 4, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 0, 4, 3, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 0, 4, 3, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 1, 3, 3, 0],\n",
       "  [0, 0, 1, 0, 0],\n",
       "  [0, 1, 3, 3, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 1, 3, 3, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 2, 2, 3, 0],\n",
       "  [0, 0, 1, 0, 0],\n",
       "  [0, 2, 2, 3, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 2, 2, 3, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 3, 1, 3, 0],\n",
       "  [0, 0, 1, 0, 0],\n",
       "  [0, 3, 1, 3, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 3, 1, 3, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 4, 0, 3, 0],\n",
       "  [0, 0, 1, 0, 0],\n",
       "  [0, 4, 0, 3, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 4, 0, 3, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 0, 5, 2, 0],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 0, 5, 2, 0],\n",
       "  [0, 1, 0, 0, 0],\n",
       "  [0, 1, 4, 2, 0],\n",
       "  [0, 0, 1, 0, 0],\n",
       "  [0, 1, 4, 2, 3]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load config\n",
    "\n",
    "data_path  = f\"data/border_basis/GF31_n=3_deg=4_terms=10_bounds=4_4_4_total=4\"\n",
    "\n",
    "\n",
    "import yaml\n",
    "with open(f'{data_path}/config.yaml', 'r') as f:\n",
    "    exp_config = yaml.safe_load(f)\n",
    "\n",
    "data_path  = f\"data/expansion/GF31_n=3_deg=4_terms=10_bounds=4_4_4_total=4\"\n",
    "\n",
    "from src.loader.data_format.processors.expansion import ExtractKLeadingTermsProcessor\n",
    "from src.loader.data_format.processors.subprocessors import MonomialProcessorPlus\n",
    "\n",
    "\n",
    "data_collator_name = 'monomial'\n",
    "\n",
    "_processors = []\n",
    "_processors.append(ExtractKLeadingTermsProcessor(config.num_leading_terms))\n",
    "\n",
    "subprocessors = {}\n",
    "subprocessors['monomial_ids'] = MonomialProcessorPlus(\n",
    "            num_variables=config.num_variables,\n",
    "            max_degree=config.max_degree,\n",
    "            max_coef=int(config.field[2:])  # 'GF7' -> 7\n",
    "        )\n",
    "\n",
    "processor = ProcessorChain(_processors) \n",
    "\n",
    "# load test dataset\n",
    "test_data_path = Path(data_path) / 'test'\n",
    "test_dataset, data_collator = load_data(\n",
    "    data_path=test_data_path,\n",
    "    processor=processor,\n",
    "    subprocessors=subprocessors,\n",
    "    splits=[{\"name\": \"test\", \"batch_size\": 32, \"shuffle\": False}],\n",
    "    tokenizer=tokenizer,\n",
    "    return_dataloader=False,  # return dataloader if True\n",
    "    data_collator_name=data_collator_name\n",
    ")\n",
    "\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.misc.utils import to_cuda\n",
    "data_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "batch = next(iter(data_loader))\n",
    "batch = to_cuda(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9823, loss: 0.0771\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    preds = outputs['logits'].argmax(dim=-1)\n",
    "    labels = batch['labels']\n",
    "    # acc = (preds[labels != -100] == labels[labels != -100]).float().mean()\n",
    "    acc = (preds[labels != -100] == labels[labels != -100]).float().mean().item()\n",
    "    loss = outputs['loss'].item()\n",
    "\n",
    "print(f'acc: {acc:.4f}, loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 0.0177, loss: 0.0771\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    ignore_index = -100\n",
    "    outputs = model(**batch)\n",
    "    logits = outputs['logits']\n",
    "    labels = batch['labels']\n",
    "\n",
    "    valid_mask = labels != ignore_index\n",
    "    valid_labels = labels[valid_mask]\n",
    "    valid_logits = logits[valid_mask]\n",
    "\n",
    "    predictions = torch.argmax(valid_logits, dim=-1)\n",
    "    \n",
    "    # acc = (preds[labels != -100] == labels[labels != -100]).float().mean()\n",
    "    error = (predictions != valid_labels).float().mean().item()\n",
    "    loss = outputs['loss'].item()\n",
    "\n",
    "print(f'error: {error:.4f}, loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader.data_format.processors.subprocessors import MonomialProcessorPlus\n",
    "\n",
    "max_length = batch['labels'].shape[-1] + 1\n",
    "mpp = MonomialProcessorPlus(num_variables=config.num_variables, max_degree=config.max_degree, max_coef=int(config.field[2:]))\n",
    "generated = model.generate(batch['input_ids'], batch['attention_mask'], \n",
    "                           monomial_processor=mpp, tokenizer=tokenizer, \n",
    "                           max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions  = mpp.batch_decode(generated, skip_special_tokens=True)\n",
    "\n",
    "labels = batch['labels']\n",
    "labels[labels == -100] = tokenizer.pad_token_id\n",
    "labels = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of predicted expansions: 50\n",
      " # of ground truth expansions: 28\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction                | Ground Truth              | Correct\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Direction   | Leading Trm | Direction   | Leading Trm | Direc. | LT    | Both \n",
      "----------------------------------------------------------------------------------------------------\n",
      "C1 E1 E0 E0  |  C1 E4 E1 E0  | C1 E1 E0 E0  |  C1 E4 E1 E0  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E4 E1 E0  |  C1 E0 E1 E0  |  C1 E4 E1 E0  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E4 E1 E0  |  C1 E0 E0 E1  |  C1 E4 E1 E0  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E5 E0 E0  |  C1 E1 E0 E0  |  C1 E5 E0 E0  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E5 E0 E0  |  C1 E0 E1 E0  |  C1 E5 E0 E0  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E5 E0 E0  |  C1 E0 E0 E1  |  C1 E5 E0 E0  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E0 E0 E6  |  C1 E1 E0 E0  |  C1 E0 E0 E6  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E0 E0 E6  |  C1 E0 E1 E0  |  C1 E0 E0 E6  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E0 E0 E6  |  C1 E0 E0 E1  |  C1 E0 E0 E6  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E0 E1 E5  |  C1 E1 E0 E0  |  C1 E0 E1 E5  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E0 E1 E5  |  C1 E0 E1 E0  |  C1 E0 E1 E5  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E0 E1 E5  |  C1 E0 E0 E1  |  C1 E0 E1 E5  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E1 E0 E5  |  C1 E1 E0 E0  |  C1 E1 E0 E5  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E1 E0 E5  |  C1 E0 E1 E0  |  C1 E1 E0 E5  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E1 E0 E5  |  C1 E0 E0 E1  |  C1 E1 E0 E5  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E0 E2 E4  |  C1 E1 E0 E0  |  C1 E0 E2 E4  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E0 E2 E4  |  C1 E0 E1 E0  |  C1 E0 E2 E4  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E0 E2 E4  |  C1 E0 E0 E1  |  C1 E0 E2 E4  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E1 E1 E4  |  C1 E1 E0 E0  |  C1 E1 E1 E4  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E1 E1 E4  |  C1 E0 E1 E0  |  C1 E1 E1 E4  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E1 E1 E4  |  C1 E0 E0 E1  |  C1 E1 E1 E4  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E2 E0 E4  |  C1 E1 E0 E0  |  C1 E2 E0 E4  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E2 E0 E4  |  C1 E0 E1 E0  |  C1 E2 E0 E4  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E2 E0 E4  |  C1 E0 E0 E1  |  C1 E2 E0 E4  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E0 E3 E3  |  C1 E1 E0 E0  |  C1 E0 E3 E3  | True   | True   | True  \n",
      " C1 E0 E1 E0  |  C1 E0 E3 E3  |  C1 E0 E1 E0  |  C1 E0 E3 E3  | True   | True   | True  \n",
      " C1 E0 E0 E1  |  C1 E0 E3 E3  |  C1 E0 E0 E1  |  C1 E0 E3 E3  | True   | True   | True  \n",
      " C1 E1 E0 E0  |  C1 E1 E2 E3  |  C1 E1 E0 E0  |  C1 E1 E2 E3 | True   | False  | False \n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "preds = predictions[idx].split('[SEP]')\n",
    "pred_directions, pred_leading_terms = preds[::2], preds[1::2]\n",
    "\n",
    "gts = labels[idx].split('[SEP]')\n",
    "gt_directions, gt_leading_terms = gts[::2], gts[1::2]\n",
    "\n",
    "\n",
    "print(f' # of predicted expansions: {len(pred_directions)}')\n",
    "print(f' # of ground truth expansions: {len(gt_directions)}')\n",
    "\n",
    "print('-'*100)\n",
    "print(f'{\"Prediction\":<25} | {\"Ground Truth\":<25} | {\"Correct\":<5}')\n",
    "print('-'*100)\n",
    "print(f'{\"Direction\":<11} | {\"Leading Trm\":<10} | {\"Direction\":<11} | {\"Leading Trm\":<10} | {\"Direc.\":<5} | {\"LT\":<5} | {\"Both\":<5}')\n",
    "print('-'*100)\n",
    "for pred_direction, pred_leading_term, gt_direction, gt_leading_term in zip(pred_directions, pred_leading_terms, gt_directions, gt_leading_terms):\n",
    "    \n",
    "    direction_correct = pred_direction   == gt_direction\n",
    "    lt_correct = pred_leading_term == gt_leading_term\n",
    "    both_correct = direction_correct and lt_correct\n",
    "    \n",
    "    print(f'{pred_direction} | {pred_leading_term} | {gt_direction} | {gt_leading_term} | {str(direction_correct):<6} | {str(lt_correct):<6} | {str(both_correct):<6}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "out of range integral type conversion attempted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# predictions  = mpp.batch_decode(generated, skip_special_tokens=True)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3820\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3797\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3798\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3802\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3818\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   3821\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m   3822\u001b[0m             seq,\n\u001b[1;32m   3823\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   3824\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   3825\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3826\u001b[0m         )\n\u001b[1;32m   3827\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3828\u001b[0m     ]\n",
      "File \u001b[0;32m/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3821\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3797\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3798\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3802\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3818\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m-> 3821\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3822\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3823\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3824\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3826\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3827\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3828\u001b[0m     ]\n",
      "File \u001b[0;32m/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3860\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3860\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:668\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    667\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 668\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    671\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    674\u001b[0m )\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mOverflowError\u001b[0m: out of range integral type conversion attempted"
     ]
    }
   ],
   "source": [
    "# predictions  = mpp.batch_decode(generated, skip_special_tokens=True)\n",
    "labels = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n",
      "torch.Size([490])\n"
     ]
    }
   ],
   "source": [
    "for l in batch['labels']:\n",
    "    print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], decoder_input_ids=batch['decoder_input_ids'], decoder_attention_mask=batch['decoder_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1298, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "preds = outputs['logits'].argmax(dim=-1)\n",
    "\n",
    "outputs['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   5,   36,   36,  ..., -100, -100, -100],\n",
       "        [  63, -100, -100,  ..., -100, -100, -100],\n",
       "        [   5,   37,   36,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [   5,   37,   36,  ..., -100, -100, -100],\n",
       "        [   5,   37,   36,  ..., -100, -100, -100],\n",
       "        [   5,   36,   36,  ..., -100, -100, -100]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3199, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = batch['labels'] != 61\n",
    "(preds[valid] == batch['labels'][valid]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "out of range integral type conversion attempted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(preds[\u001b[38;5;28mid\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m [SEP] \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m decoded_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m [SEP] \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m [[a, b, a\u001b[38;5;241m==\u001b[39mb] \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(decoded_preds, decoded_labels)]\n",
      "File \u001b[0;32m/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3860\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3860\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:668\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    667\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 668\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    671\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    674\u001b[0m )\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mOverflowError\u001b[0m: out of range integral type conversion attempted"
     ]
    }
   ],
   "source": [
    "id = 10\n",
    "decoded_preds = tokenizer.decode(preds[id], skip_special_tokens=True).split(' [SEP] ')\n",
    "decoded_labels = tokenizer.decode(batch['labels'][id], skip_special_tokens=True).split(' [SEP] ')\n",
    "[[a, b, a==b] for a, b in zip(decoded_preds, decoded_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_labels = tokenizer.decode(batch['labels'][2], skip_special_tokens=True).split(' [SEP] ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C1 E0 E0 E1 [SEP]', 'C1 E1 E0 E0', False]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[a, b, a==b] for a, b in zip(decoded_preds, decoded_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.all import *\n",
    "ring = PolynomialRing(GF(31), 'x', 3, order='degrevlex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unable to convert '' to an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[249], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m decoded_texts[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43msequence_to_poly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded_texts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mring\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/dataset/processors/utils.py:41\u001b[0m, in \u001b[0;36msequence_to_poly\u001b[0;34m(seq, ring)\u001b[0m\n\u001b[1;32m     38\u001b[0m         coeff \u001b[38;5;241m=\u001b[39m m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     39\u001b[0m         ex \u001b[38;5;241m=\u001b[39m m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 41\u001b[0m     d[\u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mint\u001b[39m(ei[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;28;01mfor\u001b[39;00m ei \u001b[38;5;129;01min\u001b[39;00m ex])] \u001b[38;5;241m=\u001b[39m \u001b[43mfield\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# if seq != poly_to_sequence(ring(d)):\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#     print(seq)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#     print(ring(d))\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#     assert(seq == poly_to_sequence(ring(d)))\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ring(d)\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/structure/parent.pyx:908\u001b[0m, in \u001b[0;36msage.structure.parent.Parent.__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    906\u001b[0m if mor is not None:\n\u001b[1;32m    907\u001b[0m     if no_extra_args:\n\u001b[0;32m--> 908\u001b[0m         return mor._call_(x)\n\u001b[1;32m    909\u001b[0m     else:\n\u001b[1;32m    910\u001b[0m         return mor._call_with_args(x, args, kwds)\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/structure/coerce_maps.pyx:164\u001b[0m, in \u001b[0;36msage.structure.coerce_maps.DefaultConvertMap_unique._call_\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m             print(type(C), C)\n\u001b[1;32m    163\u001b[0m             print(type(C._element_constructor), C._element_constructor)\n\u001b[0;32m--> 164\u001b[0m         raise\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m cpdef Element _call_with_args(self, x, args=(), kwds={}):\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/structure/coerce_maps.pyx:159\u001b[0m, in \u001b[0;36msage.structure.coerce_maps.DefaultConvertMap_unique._call_\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m cdef Parent C = self._codomain\n\u001b[1;32m    158\u001b[0m try:\n\u001b[0;32m--> 159\u001b[0m     return C._element_constructor(x)\n\u001b[1;32m    160\u001b[0m except Exception:\n\u001b[1;32m    161\u001b[0m     if print_warnings:\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/rings/finite_rings/integer_mod_ring.py:1176\u001b[0m, in \u001b[0;36mIntegerModRing_generic._element_constructor_\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03mTESTS::\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minteger_mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIntegerMod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, PariError):\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror coercing to finite field\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/rings/finite_rings/integer_mod.pyx:204\u001b[0m, in \u001b[0;36msage.rings.finite_rings.integer_mod.IntegerMod\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m         return a\n\u001b[1;32m    203\u001b[0m t = modulus.element_class()\n\u001b[0;32m--> 204\u001b[0m return t(parent, value)\n\u001b[1;32m    205\u001b[0m \n\u001b[1;32m    206\u001b[0m \n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/rings/finite_rings/integer_mod.pyx:402\u001b[0m, in \u001b[0;36msage.rings.finite_rings.integer_mod.IntegerMod_abstract.__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    400\u001b[0m             z = value % self._modulus.sageInteger\n\u001b[1;32m    401\u001b[0m         else:\n\u001b[0;32m--> 402\u001b[0m             raise\n\u001b[1;32m    403\u001b[0m self.set_from_mpz(z.value)\n\u001b[1;32m    404\u001b[0m \n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/rings/finite_rings/integer_mod.pyx:391\u001b[0m, in \u001b[0;36msage.rings.finite_rings.integer_mod.IntegerMod_abstract.__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    389\u001b[0m else:\n\u001b[1;32m    390\u001b[0m     try:\n\u001b[0;32m--> 391\u001b[0m         z = integer_ring.Z(value)\n\u001b[1;32m    392\u001b[0m     except (TypeError, ValueError):\n\u001b[1;32m    393\u001b[0m         from sage.structure.element import Expression\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/structure/parent.pyx:908\u001b[0m, in \u001b[0;36msage.structure.parent.Parent.__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    906\u001b[0m if mor is not None:\n\u001b[1;32m    907\u001b[0m     if no_extra_args:\n\u001b[0;32m--> 908\u001b[0m         return mor._call_(x)\n\u001b[1;32m    909\u001b[0m     else:\n\u001b[1;32m    910\u001b[0m         return mor._call_with_args(x, args, kwds)\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/structure/coerce_maps.pyx:164\u001b[0m, in \u001b[0;36msage.structure.coerce_maps.DefaultConvertMap_unique._call_\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m             print(type(C), C)\n\u001b[1;32m    163\u001b[0m             print(type(C._element_constructor), C._element_constructor)\n\u001b[0;32m--> 164\u001b[0m         raise\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m cpdef Element _call_with_args(self, x, args=(), kwds={}):\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/structure/coerce_maps.pyx:159\u001b[0m, in \u001b[0;36msage.structure.coerce_maps.DefaultConvertMap_unique._call_\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m cdef Parent C = self._codomain\n\u001b[1;32m    158\u001b[0m try:\n\u001b[0;32m--> 159\u001b[0m     return C._element_constructor(x)\n\u001b[1;32m    160\u001b[0m except Exception:\n\u001b[1;32m    161\u001b[0m     if print_warnings:\n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/rings/integer.pyx:681\u001b[0m, in \u001b[0;36msage.rings.integer.Integer.__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    679\u001b[0m if '_' in x:\n\u001b[1;32m    680\u001b[0m     x = x.replace('_', '')\n\u001b[0;32m--> 681\u001b[0m mpz_set_str_python(self.value, str_to_bytes(x), base)\n\u001b[1;32m    682\u001b[0m return\n\u001b[1;32m    683\u001b[0m \n",
      "File \u001b[0;32m/data/kera/workspace/sage/src/sage/rings/integer.pyx:7343\u001b[0m, in \u001b[0;36msage.rings.integer.mpz_set_str_python\u001b[0;34m()\u001b[0m\n\u001b[1;32m   7341\u001b[0m assert base >= 2\n\u001b[1;32m   7342\u001b[0m if mpz_set_str(z, x, base) != 0:\n\u001b[0;32m-> 7343\u001b[0m     raise TypeError(\"unable to convert %r to an integer\" % char_to_str(s))\n\u001b[1;32m   7344\u001b[0m if sign < 0:\n\u001b[1;32m   7345\u001b[0m     mpz_neg(z, z)\n",
      "\u001b[0;31mTypeError\u001b[0m: unable to convert '' to an integer"
     ]
    }
   ],
   "source": [
    "decoded_texts[0]\n",
    "sequence_to_poly(decoded_texts[0], ring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1 E0 E1 E0 [SEP] C1 E3 E4 E0 [SEP]',\n",
       " 'C1 E0 E0 E1 [SEP]',\n",
       " 'C1 E0 E1 E0 [SEP] C1 E0 E5 E1 [SEP] C1 E0 E1 E0 [SEP] C1 E1 E4 E0 [SEP] C1 E0 E0 E1 [SEP] C1 E1 E4 E0 [SEP] C1 E0 E1 E0 [SEP] C1 E0 E4 E2 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E3 E0 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E3 E0 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E2 E0 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E2 E0 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E2 E0 [SEP] C1 E1 E0 E0 [SEP] C1 E1 E3 E1 [SEP] C1 E0 E1 E0 [SEP] C1 E1 E3 E1 [SEP] C1 E0 E0 E1 [SEP] C1 E0 E3 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E0 E3 E3',\n",
       " 'C1 E1 E0 E0 [SEP] C1 E0 E2 E1 [SEP] C1 E1 E1 E0 [SEP] C1 E1 E6 E0 [SEP] C1 E0 E0 E1 [SEP] C1 E0 E6 E0 [SEP] C1 E1 E0 E0 [SEP] C1 E4 E1 E1 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E1 E1 [SEP] C1 E0 E0 E1 [SEP] C1 E2 E3 E1 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E1 E2 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E1 E2 [SEP] C1 E0 E0 E1 [SEP] C1 E1 E3 E2 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E0 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E0 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E0 E3 [SEP] C1 E1 E0 E0 [SEP] C1 E2 E1 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E2 E1 E3 [SEP]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset.processors.utils import sequence_to_poly\n",
    "decoded_texts = tokenizer.batch_decode(preds[:, :-1], skip_special_tokens=True)\n",
    "# decoded_texts = [sequence_to_poly(text, ring) for text in decoded_texts]\n",
    "# decoded_texts = [dt.split()[:-1] if dt else dt for dt in decoded_texts]\n",
    "decoded_texts[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1 E0 E0 E1 [SEP] C1 E1 E3 E1',\n",
       " '',\n",
       " 'C1 E1 E0 E0 [SEP] C1 E1 E4 E0 [SEP] C1 E0 E1 E0 [SEP] C1 E1 E4 E0 [SEP] C1 E0 E0 E1 [SEP] C1 E1 E4 E0 [SEP] C1 E0 E1 E0 [SEP] C1 E0 E4 E2 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E3 E0 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E3 E0 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E2 E0 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E2 E0 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E2 E0 [SEP] C1 E1 E0 E0 [SEP] C1 E1 E3 E1 [SEP] C1 E0 E1 E0 [SEP] C1 E1 E3 E1 [SEP] C1 E1 E0 E0 [SEP] C1 E0 E3 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E0 E3 E3',\n",
       " 'C1 E0 E0 E1 [SEP] C1 E2 E2 E2 [SEP] C1 E0 E0 E1 [SEP] C1 E1 E5 E0 [SEP] C1 E0 E0 E1 [SEP] C1 E1 E4 E1 [SEP] C1 E0 E0 E1 [SEP] C1 E5 E0 E1 [SEP] C1 E0 E1 E0 [SEP] C1 E2 E3 E1 [SEP] C1 E0 E0 E1 [SEP] C1 E4 E0 E2 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E1 E2 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E1 E2 [SEP] C1 E0 E1 E0 [SEP] C1 E1 E3 E2 [SEP] C1 E1 E0 E0 [SEP] C1 E3 E0 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E3 E0 E3 [SEP] C1 E0 E0 E1 [SEP] C1 E3 E0 E3 [SEP] C1 E1 E0 E0 [SEP] C1 E2 E1 E3 [SEP] C1 E0 E1 E0 [SEP] C1 E2 E1 E3']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = batch['labels']\n",
    "labels[labels == -100] = tokenizer.pad_token_id\n",
    "tokenizer.batch_decode(labels, skip_special_tokens=True)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True]], device='cuda:0')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'] != tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   5,   36,   36,  ...,   61,   61,   61],\n",
       "        [  63,   61,   61,  ...,   61,   61,   61],\n",
       "        [   5,   37,   36,  ...,   61,   61,   61],\n",
       "        ...,\n",
       "        [   5,   37,   36,  ...,   61,   61,   61],\n",
       "        [-100, -100, -100,  ..., -100, -100, -100],\n",
       "        [-100, -100, -100,  ..., -100, -100, -100]], device='cuda:0')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(4.4995, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[[-10.4059, -11.4984, -11.2304,  ...,   2.4077, -11.6887, -10.7370],\n",
       "         [-24.4693, -24.6680, -24.6922,  ...,  -5.3014, -24.6362, -24.7874],\n",
       "         [-23.0536, -23.1035, -23.4083,  ...,  -5.1396, -23.3535, -23.2488],\n",
       "         ...,\n",
       "         [-14.9247, -15.0943, -14.7434,  ...,  -1.2014, -14.9254, -14.8689],\n",
       "         [-13.3075, -13.2106, -13.1984,  ...,  -0.9993, -13.3745, -13.1659],\n",
       "         [-19.1048, -19.0126, -19.1906,  ...,  -9.4646, -19.0795, -18.9107]],\n",
       "\n",
       "        [[-10.8350, -11.7923, -11.5299,  ...,   2.7475, -12.0603, -11.1324],\n",
       "         [-23.8303, -24.0153, -24.0074,  ...,  -4.8655, -23.9860, -24.0805],\n",
       "         [-22.7361, -22.7236, -23.0216,  ...,  -5.2049, -23.1075, -22.9658],\n",
       "         ...,\n",
       "         [-11.5923, -11.5744, -12.0024,  ...,  -3.6673, -12.0274, -11.6766],\n",
       "         [-17.0731, -16.8038, -17.0046,  ...,  -3.3900, -17.1154, -16.9577],\n",
       "         [-10.8845, -10.5951, -10.5068,  ...,  17.6736, -10.9152, -10.7931]],\n",
       "\n",
       "        [[-10.4485, -11.5786, -11.2350,  ...,   3.1674, -11.9440, -11.0279],\n",
       "         [-23.0604, -23.3197, -23.4489,  ...,  -5.4434, -23.1869, -23.3519],\n",
       "         [-24.8553, -24.9582, -25.3908,  ...,  -5.9987, -25.2331, -25.2315],\n",
       "         ...,\n",
       "         [-14.2584, -14.4165, -14.1584,  ...,  -1.4872, -14.2634, -14.2208],\n",
       "         [-12.2795, -12.1508, -12.1550,  ...,  -0.8931, -12.3122, -12.1233],\n",
       "         [-19.8522, -19.6581, -19.7938,  ...,  -8.1095, -19.7302, -19.4886]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-11.2760, -12.0983, -11.8674,  ...,   2.4701, -12.5654, -11.7930],\n",
       "         [-24.4400, -24.4901, -24.9337,  ...,  -4.7350, -24.4174, -24.6108],\n",
       "         [-23.6690, -23.9743, -24.1677,  ...,  -5.1023, -24.1121, -24.1275],\n",
       "         ...,\n",
       "         [-13.8867, -13.9916, -13.7066,  ...,  -1.4731, -13.8329, -13.8700],\n",
       "         [-11.1286, -10.9716, -10.9936,  ...,  -0.8119, -11.1263, -10.9424],\n",
       "         [-18.6979, -18.4757, -18.7281,  ..., -11.7555, -18.5291, -18.3693]],\n",
       "\n",
       "        [[-13.0235, -13.7604, -13.2693,  ...,   1.5415, -13.8122, -13.1954],\n",
       "         [-26.3786, -26.2052, -26.7452,  ...,  -6.7760, -26.5765, -26.4570],\n",
       "         [-26.4623, -26.6337, -26.6815,  ...,  -6.4507, -26.6772, -26.7930],\n",
       "         ...,\n",
       "         [-13.7567, -13.8585, -13.5942,  ...,  -1.1648, -13.7856, -13.7402],\n",
       "         [-12.0204, -11.9015, -11.9397,  ...,  -0.6836, -12.0017, -11.8384],\n",
       "         [-19.1027, -18.9416, -19.0717,  ..., -11.6514, -19.0123, -18.7786]],\n",
       "\n",
       "        [[-10.0609, -10.9946, -10.6714,  ...,   2.4272, -11.1178, -10.3517],\n",
       "         [-20.8217, -20.6520, -20.9996,  ...,  -5.9076, -20.8521, -20.5092],\n",
       "         [-21.0595, -21.1308, -21.3044,  ...,  -5.2010, -21.3879, -21.3757],\n",
       "         ...,\n",
       "         [-13.2080, -13.2595, -12.9734,  ...,  -1.1593, -13.2040, -13.1157],\n",
       "         [-11.5004, -11.3139, -11.3160,  ...,  -0.7361, -11.4626, -11.2321],\n",
       "         [-17.6777, -17.4769, -17.5504,  ..., -14.3368, -17.5178, -17.3024]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-6.7701e-01, -5.2752e-01, -1.1775e-02,  ...,  2.5658e-01,\n",
       "          -9.3290e-01, -6.5080e-02],\n",
       "         [-6.2984e-02,  4.0665e-01, -6.6899e-02,  ...,  8.2718e-01,\n",
       "          -8.0930e-01, -5.8370e-01],\n",
       "         [-4.7855e-01,  6.0436e-01,  6.8216e-01,  ...,  1.6804e+00,\n",
       "          -2.4643e+00, -4.9686e-01],\n",
       "         ...,\n",
       "         [-7.1250e-01, -7.7436e-02,  4.1184e-01,  ...,  1.5689e+00,\n",
       "          -1.8730e-01,  5.9312e-02],\n",
       "         [-9.1503e-01, -3.0668e-01,  6.2773e-01,  ...,  1.0966e+00,\n",
       "          -3.3179e-01,  2.2889e-01],\n",
       "         [-7.2738e-01, -2.8381e-01,  2.2796e-01,  ...,  1.9999e+00,\n",
       "          -1.7687e-01, -3.6075e-01]],\n",
       "\n",
       "        [[-5.6268e-01, -8.5309e-01, -7.6857e-01,  ...,  3.5163e-01,\n",
       "          -9.2551e-01, -2.3351e-01],\n",
       "         [ 3.5687e-01,  3.1069e-01, -1.1315e+00,  ...,  1.2188e+00,\n",
       "          -5.5369e-01, -3.0106e-01],\n",
       "         [ 4.4153e-03,  6.9273e-01, -2.4450e-01,  ...,  1.2279e+00,\n",
       "          -2.3837e+00, -3.2445e-01],\n",
       "         ...,\n",
       "         [-7.3073e-01, -3.7122e-01,  4.9513e-01,  ...,  9.6561e-01,\n",
       "           2.0560e-01,  1.6516e-01],\n",
       "         [-9.3455e-01, -4.9450e-01,  5.8504e-01,  ...,  6.5805e-01,\n",
       "           6.3211e-02,  4.0986e-01],\n",
       "         [-7.1583e-01, -5.2646e-01,  2.4884e-01,  ...,  1.4960e+00,\n",
       "           1.3348e-01, -2.1955e-01]],\n",
       "\n",
       "        [[ 3.2062e-01, -2.6518e-01, -8.7355e-02,  ..., -1.4795e-01,\n",
       "          -4.1375e-01, -1.6415e-01],\n",
       "         [ 7.1434e-01, -5.5455e-01, -7.7119e-02,  ...,  3.1424e-01,\n",
       "          -1.9185e-01,  3.4242e-01],\n",
       "         [ 4.9188e-01,  7.8973e-01,  5.7271e-01,  ..., -1.2363e-01,\n",
       "          -2.1468e+00,  7.7090e-01],\n",
       "         ...,\n",
       "         [-6.0957e-01,  1.1212e-01,  5.5135e-01,  ...,  9.8097e-01,\n",
       "           6.0991e-01,  6.9487e-01],\n",
       "         [-8.5813e-01, -1.3102e-01,  6.6383e-01,  ...,  6.3894e-01,\n",
       "           5.0844e-01,  7.7898e-01],\n",
       "         [-7.4656e-01, -2.1598e-01,  3.5755e-01,  ...,  1.6562e+00,\n",
       "           4.1630e-01,  2.9261e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.2939e-01,  3.1237e-02, -3.9975e-01,  ...,  4.2882e-02,\n",
       "           1.5672e-01,  7.1295e-02],\n",
       "         [ 5.7559e-01,  2.2386e+00,  1.0252e-01,  ..., -7.1131e-01,\n",
       "           5.0253e-01,  1.5262e-01],\n",
       "         [ 2.1333e-01,  7.6648e-01, -1.6462e-02,  ...,  2.5475e-01,\n",
       "          -1.1862e+00, -1.1720e+00],\n",
       "         ...,\n",
       "         [ 2.1846e-01,  5.0995e-01,  4.7618e-02,  ...,  1.7492e+00,\n",
       "          -2.0687e-01, -7.7443e-01],\n",
       "         [ 7.4838e-02,  6.1524e-02,  3.2586e-01,  ...,  1.6263e+00,\n",
       "          -2.9903e-01, -4.4819e-01],\n",
       "         [-1.0173e-01,  1.5000e-01, -5.1507e-03,  ...,  2.6253e+00,\n",
       "          -1.9994e-01, -8.1062e-01]],\n",
       "\n",
       "        [[ 5.4512e-01, -1.5003e-01, -5.2690e-01,  ..., -2.8910e-01,\n",
       "           4.9887e-01,  2.3120e-01],\n",
       "         [ 1.1599e+00,  1.5957e+00,  2.1827e-01,  ..., -3.2178e-01,\n",
       "           8.5111e-01,  8.2741e-01],\n",
       "         [ 1.5729e+00,  5.0885e-01, -1.9315e-03,  ..., -6.4593e-02,\n",
       "          -6.2993e-01, -1.5374e+00],\n",
       "         ...,\n",
       "         [ 4.5019e-01,  6.5866e-01,  8.8858e-01,  ...,  1.0434e+00,\n",
       "           5.6457e-01, -2.7398e-01],\n",
       "         [ 5.1793e-01,  1.4237e-01,  8.3336e-01,  ...,  5.6591e-01,\n",
       "           7.1490e-01, -1.5916e-01],\n",
       "         [ 4.4726e-01,  9.1628e-02,  5.6993e-01,  ...,  1.4551e+00,\n",
       "           7.0506e-01, -4.2219e-01]],\n",
       "\n",
       "        [[ 1.1739e-01, -2.2450e-01,  1.5281e-01,  ...,  2.1450e-01,\n",
       "           3.1187e-01,  2.2096e-01],\n",
       "         [ 5.8492e-01,  1.1599e+00,  1.2729e-01,  ..., -6.4836e-01,\n",
       "           9.6097e-01,  3.9319e-01],\n",
       "         [ 1.3991e+00,  5.5570e-02,  6.8526e-01,  ...,  3.9363e-03,\n",
       "          -1.1969e-01, -1.0553e+00],\n",
       "         ...,\n",
       "         [ 4.8099e-01,  6.1702e-01,  1.7219e+00,  ...,  1.5637e+00,\n",
       "           2.3183e-01, -2.2449e-01],\n",
       "         [ 4.7096e-01,  2.1015e-01,  1.7640e+00,  ...,  8.9506e-01,\n",
       "           2.7526e-01, -1.1080e-01],\n",
       "         [ 5.0965e-01,  4.2710e-02,  1.3288e+00,  ...,  1.7921e+00,\n",
       "           2.9802e-01, -1.7554e-01]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader.data_format.processors.subprocessors import MonomialProcessorPlus\n",
    "\n",
    "mpp = MonomialProcessorPlus(num_variables=3, max_degree=20, max_coef=31)\n",
    "\n",
    "generated = model.generate(batch['input_ids'], batch['attention_mask'], monomial_processor=mpp, tokenizer=tokenizer, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E0 E0 E0 [BOS] C1 E0 E0 E0 [EOS] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP] C1 E0 E0 E0 [SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mpp.decode(generated[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.loader.models.custom_bart failed: Traceback (most recent call last):\n",
      "  File \"/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: generate() requires a code object with 0 free vars, not 2\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 2],\n",
       "        [0, 0, 0, 0, 3],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, True]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monomials = ['[PAD] E1 E0 E0 [SEP]', '[PAD] [PAD] [PAD] [PAD] [PAD]', '[PAD] E1 E0 E0 [SEP]', 'C1 E0 E0 E1 [SEP]', 'C1 E0 E0 E1 </s>', 'C1 E1 E1 E0 </s>', '[PAD] [PAD] [PAD] [PAD] </s>', '[PAD] E1 E0 E0 [SEP]', 'C1 E0 E0 E1 [SEP]', 'C1 E0 E0 E1 </s>', 'C1 E1 E1 E0 </s>', '[PAD] [PAD] [PAD] [PAD] </s>', '[PAD] E1 E0 E0 [SEP]', 'C1 E0 E0 E1 [SEP]', 'C1 E0 E0 E1 </s>', 'C1 E1 E1 E0 </s>', '[PAD] [PAD] [PAD] [PAD] </s>', '[PAD] E1 E0 E0 [SEP]', 'C1 E0 E0 E1 [SEP]', 'C1 E0 E0 E1 </s>', 'C1 E1 E1 E0 </s>', '[PAD] [PAD] [PAD] [PAD] </s>', 'C1 E0 E0 E1 [SEP]', 'C1 E0 E0 E1 [SEP]', 'C1 E1 E0 E0 [SEP]', 'C1 E0 E0 E1 [SEP]', 'C1 E0 E0 E1 </s>', 'C1 E1 E1 E0 </s>', 'C1 E1 E0 E0 </s>', 'C1 E1 E0 E0 [SEP]', 'C1 E0 E0 E1 [SEP]', 'C1 E0 E0 E1 </s>']\n",
    "mpp.is_valid_monomial(monomials[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 3], [0, 0, 0, 0, 3], [0, 0, 0, 0, 3], [(0, 0, 0, 1, 0)]]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpp.generation_helper(monomials[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/131 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'preds' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generation_accuracy\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgeneration_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sage/local/var/lib/sage/venv-python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/evaluation/generation.py:146\u001b[0m, in \u001b[0;36mgeneration_accuracy\u001b[0;34m(model, dataloader, batch_size, max_length, tokenizer, th, disable_tqdm, modulo, model_name, quantize_fn, from_checkpoint, compute_support_acc, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_length, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    145\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 146\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mgeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantize_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantize_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    148\u001b[0m runtime \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/src/evaluation/generation.py:48\u001b[0m, in \u001b[0;36mgeneration\u001b[0;34m(model, model_name, batch, tokenizer, max_length, quantize_fn)\u001b[0m\n\u001b[1;32m     45\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_vectors\u001b[39m\u001b[38;5;124m'\u001b[39m: preds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_token_types\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenizer\u001b[38;5;241m.\u001b[39mget_token_types(preds)}\n\u001b[1;32m     46\u001b[0m     preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode_vectors(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpreds\u001b[49m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'preds' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from src.evaluation.generation import generation_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[id]['input'].split(' [BIGSEP] ')[2])\n",
    "print(test_dataset[id]['input'].split(' [BIGSEP] ')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 230\n",
    "\n",
    "trainset_V = [train_sample['input'].split(' [BIGSEP] ') for train_sample in train_dataset]\n",
    "testset_V = [test_sample['input'].split(' [BIGSEP] ') for test_sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for test_V in enumerate(testset_V):\n",
    "    print(test_V in trainset_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls_input = []\n",
    "Ls_target = []\n",
    "for sample in test_dataset:\n",
    "    length_input = len(sample['input'].split())\n",
    "    length_target = len(sample['target'].split())\n",
    "    Ls_input.append(length_input)\n",
    "    Ls_target.append(length_target)\n",
    "    # print(length)\n",
    "    # print(len(sample['target'].split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 126004, 9539.8, 10897.5\n",
      "target: 37654, 3497.9, 4147.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Ls_input = np.array(Ls_input)\n",
    "Ls_target = np.array(Ls_target)\n",
    "\n",
    "print(f'input: {np.max(Ls_input)}, {np.mean(Ls_input):.1f}, {np.std(Ls_input):.1f}')\n",
    "print(f'target: {np.max(Ls_target)}, {np.mean(Ls_target):.1f}, {np.std(Ls_target):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C28 E1 E2 E1 + C2 E0 E3 E1 + C30 E1 E2 E0 + C12 E0 E3 E0 + C1 E1 E0 E2 + C5 E2 E0 E0 + C30 E1 E1 E0 + C25 E0 E2 E0 + C21 E1 E0 E1 + C10 E0 E1 E1 + C15 E0 E0 E2 + C4 E0 E1 E0 + C14 E0 E0 E1 [SEP] C10 E2 E3 E0 + C26 E3 E1 E1 + C25 E2 E0 E3 + C19 E1 E3 E0 + C7 E0 E4 E0 + C6 E2 E1 E1 + C15 E1 E2 E1 + C5 E2 E0 E2 + C15 E1 E1 E2 + C11 E1 E0 E3 + C2 E0 E1 E3 + C17 E3 E0 E0 + C2 E2 E1 E0 + C24 E1 E2 E0 + C15 E0 E3 E0 + C20 E2 E0 E1 + C8 E1 E1 E1 + C1 E0 E2 E1 + C7 E1 E0 E2 + C11 E0 E1 E2 + C23 E0 E0 E3 + C24 E2 E0 E0 + C17 E1 E1 E0 + C16 E0 E2 E0 + C27 E1 E0 E1 + C19 E0 E1 E1 + C20 E0 E0 E2 + C16 E1 E0 E0 + C24 E0 E1 E0 + C18 E0 E0 E1 + C11 E0 E0 E0 [SEP] C26 E1 E3 E1 + C7 E1 E3 E0 + C30 E0 E4 E0 + C22 E2 E1 E1 + C23 E1 E2 E1 + C5 E0 E3 E1 + C14 E2 E0 E2 + C27 E1 E1 E2 + C23 E0 E2 E2 + C24 E1 E0 E3 + C10 E0 E1 E3 + C23 E0 E0 E4 + C30 E2 E1 E0 + C10 E1 E2 E0 + C26 E0 E3 E0 + C20 E2 E0 E1 + C7 E1 E1 E1 + C18 E0 E2 E1 + C2 E1 E0 E2 + C26 E0 E0 E3 + C3 E2 E0 E0 + C1 E1 E1 E0 + C22 E0 E2 E0 + C5 E1 E0 E1 + C8 E0 E1 E1 + C18 E1 E0 E0 + C2 E0 E1 E0 + C1 E0 E0 E1 + C2 E0 E0 E0 [SEP] C18 E2 E3 E0 + C22 E1 E4 E0 + C21 E3 E1 E0 + C30 E2 E2 E0 + C22 E0 E4 E0 + C11 E2 E1 E1 + C15 E2 E1 E0 + C16 E1 E2 E0 + C8 E0 E3 E0 + C19 E2 E0 E1 + C23 E1 E1 E1 + C7 E1 E0 E2 + C5 E2 E0 E0 + C10 E1 E1 E0 + C30 E0 E2 E0 + C9 E1 E0 E1 + C19 E0 E1 E1 + C25 E1 E0 E0 + C15 E0 E1 E0 + C9 E0 E0 E1 + C14 E0 E0 E0 [SEP] C17 E2 E2 E0 + C2 E3 E0 E0 + C30 E2 E1 E0 + C7 E1 E2 E0 + C15 E0 E3 E0 + C3 E2 E0 E1 + C22 E1 E1 E1 + C7 E0 E1 E2 + C6 E1 E1 E0 + C7 E0 E2 E0 + C16 E1 E0 E1 + C4 E0 E1 E1 + C26 E1 E0 E0 + C8 E0 E1 E0 + C11 E0 E0 E1 + C20 E0 E0 E0 [SEP] C28 E1 E4 E0 + C29 E2 E2 E1 + C30 E0 E1 E4 + C16 E3 E1 E0 + C11 E2 E2 E0 + C18 E1 E3 E0 + C23 E1 E1 E2 + C5 E0 E2 E2 + C17 E1 E0 E3 + C15 E0 E1 E3 + C19 E3 E0 E0 + C20 E2 E1 E0 + C17 E1 E2 E0 + C28 E0 E3 E0 + C17 E2 E0 E1 + C23 E1 E1 E1 + C30 E0 E2 E1 + C19 E1 E0 E2 + C13 E0 E1 E2 + C25 E0 E0 E3 + C17 E2 E0 E0 + C23 E1 E1 E0 + C16 E0 E2 E0 + C7 E1 E0 E1 + C26 E0 E1 E1 + C22 E0 E0 E2 + C8 E1 E0 E0 + C15 E0 E1 E0 + C20 E0 E0 E1 + C19 E0 E0 E0 [SEP] C29 E1 E4 E0 + C16 E4 E0 E1 + C30 E0 E2 E3 + C7 E2 E2 E0 + C6 E1 E3 E0 + C18 E3 E0 E1 + C5 E2 E1 E1 + C3 E1 E1 E2 + C19 E1 E0 E3 + C6 E0 E1 E3 + C17 E1 E2 E0 + C25 E0 E3 E0 + C4 E2 E0 E1 + C5 E1 E1 E1 + C25 E0 E2 E1 + C30 E0 E0 E3 + C9 E1 E1 E0 + C13 E0 E2 E0 + C27 E1 E0 E1 + C23 E0 E1 E1 + C29 E1 E0 E0 + C7 E0 E1 E0 + C25 E0 E0 E1 + C6 E0 E0 E0 [SEP] C24 E2 E2 E1 + C18 E0 E3 E2 + C26 E3 E1 E0 + C9 E2 E2 E0 + C4 E1 E2 E1 + C30 E0 E3 E1 + C25 E1 E1 E2 + C28 E3 E0 E0 + C6 E2 E1 E0 + C9 E1 E2 E0 + C17 E0 E3 E0 + C4 E2 E0 E1 + C4 E1 E1 E1 + C13 E0 E2 E1 + C19 E1 E0 E2 + C25 E0 E1 E2 + C6 E2 E0 E0 + C4 E1 E1 E0 + C6 E0 E2 E0 + C29 E1 E0 E1 + C1 E0 E1 E1 + C28 E0 E0 E2 + C3 E1 E0 E0 + C28 E0 E1 E0 + C17 E0 E0 E1 + C17 E0 E0 E0 [SEP] C9 E3 E1 E0 + C15 E3 E0 E1 + C7 E2 E1 E0 + C8 E0 E1 E2 + C8 E2 E0 E0 + C11 E1 E1 E0 + C2 E0 E2 E0 + C22 E1 E0 E1 + C28 E0 E1 E1 + C10 E0 E0 E2 + C10 E1 E0 E0 + C9 E0 E1 E0 + C29 E0 E0 E1 + C20 E0 E0 E0 [SEP] C14 E3 E1 E0 + C20 E2 E2 E0 + C30 E2 E1 E1 + C9 E1 E2 E1 + C14 E0 E3 E1 + C7 E3 E0 E0 + C27 E2 E1 E0 + C8 E1 E2 E0 + C1 E0 E3 E0 + C17 E1 E1 E1 + C21 E0 E2 E1 + C7 E2 E0 E0 + C12 E1 E1 E0 + C22 E0 E2 E0 + C3 E1 E0 E1 + C8 E0 E1 E1 + C24 E1 E0 E0 + C23 E0 E1 E0 + C17 E0 E0 E1 + C26 E0 E0 E0 [BIGSEP] C1 E1 E1 E2 [SEP] C1 E0 E1 E4 [SEP] C1 E0 E2 E3 [SEP] C1 E2 E0 E3 [SEP] C1 E0 E3 E2 [SEP] C1 E1 E3 E1 [SEP] C1 E2 E2 E1 [SEP] C1 E3 E1 E1 [SEP] C1 E4 E0 E1 [SEP] C1 E1 E4 E0 [SEP] C1 E2 E3 E0 [BIGSEP] C1 E1 E2 E1 + C20 E0 E3 E1 + C21 E1 E2 E0 + C27 E0 E3 E0 + C10 E1 E0 E2 + C19 E2 E0 E0 + C21 E1 E1 E0 + C2 E0 E2 E0 + C24 E1 E0 E1 + C7 E0 E1 E1 + C26 E0 E0 E2 + C9 E0 E1 E0 + C16 E0 E0 E1 [SEP] C1 E2 E3 E0 + C15 E3 E1 E1 + C18 E2 E0 E3 + C5 E1 E3 E0 + C10 E0 E4 E0 + C13 E2 E1 E1 + C17 E1 E2 E1 + C16 E2 E0 E2 + C17 E1 E1 E2 + C29 E1 E0 E3 + C25 E0 E1 E3 + C11 E3 E0 E0 + C25 E2 E1 E0 + C21 E1 E2 E0 + C17 E0 E3 E0 + C2 E2 E0 E1 + C7 E1 E1 E1 + C28 E0 E2 E1 + C10 E1 E0 E2 + C29 E0 E1 E2 + C24 E0 E0 E3 + C21 E2 E0 E0 + C11 E1 E1 E0 + C14 E0 E2 E0 + C12 E1 E0 E1 + C5 E0 E1 E1 + C2 E0 E0 E2 + C14 E1 E0 E0 + C21 E0 E1 E0 + C8 E0 E0 E1 + C29 E0 E0 E0 [SEP] C1 E1 E3 E1 + C11 E1 E3 E0 + C25 E0 E4 E0 + C8 E2 E1 E1 + C14 E1 E2 E1 + C30 E0 E3 E1 + C22 E2 E0 E2 + C7 E1 E1 E2 + C14 E0 E2 E2 + C20 E1 E0 E3 + C29 E0 E1 E3 + C14 E0 E0 E4 + C25 E2 E1 E0 + C29 E1 E2 E0 + C1 E0 E3 E0 + C27 E2 E0 E1 + C11 E1 E1 E1 + C15 E0 E2 E1 + C12 E1 E0 E2 + C1 E0 E0 E3 + C18 E2 E0 E0 + C6 E1 E1 E0 + C8 E0 E2 E0 + C30 E1 E0 E1 + C17 E0 E1 E1 + C15 E1 E0 E0 + C12 E0 E1 E0 + C6 E0 E0 E1 + C12 E0 E0 E0 [SEP] C1 E1 E4 E0 + C30 E3 E1 E1 + C5 E2 E0 E3 + C8 E3 E1 E0 + C7 E2 E2 E0 + C10 E1 E3 E0 + C21 E0 E4 E0 + C11 E2 E1 E1 + C3 E1 E2 E1 + C1 E2 E0 E2 + C3 E1 E1 E2 + C27 E1 E0 E3 + C19 E0 E1 E3 + C22 E3 E0 E0 + C7 E2 E1 E0 + C23 E1 E2 E0 + C9 E0 E3 E0 + C26 E2 E0 E1 + C8 E1 E1 E1 + C25 E0 E2 E1 + C2 E1 E0 E2 + C27 E0 E1 E2 + C17 E0 E0 E3 + C7 E2 E0 E0 + C14 E1 E1 E0 + C4 E0 E2 E0 + C23 E1 E0 E1 + C1 E0 E1 E1 + C4 E0 E0 E2 + C8 E1 E0 E0 + C30 E0 E1 E0 + C15 E0 E0 E1 + C22 E0 E0 E0 [SEP] C1 E2 E2 E0 + C22 E3 E0 E0 + C20 E2 E1 E0 + C15 E1 E2 E0 + C10 E0 E3 E0 + C2 E2 E0 E1 + C25 E1 E1 E1 + C15 E0 E1 E2 + C4 E1 E1 E0 + C15 E0 E2 E0 + C21 E1 E0 E1 + C13 E0 E1 E1 + C7 E1 E0 E0 + C26 E0 E1 E0 + C28 E0 E0 E1 + C3 E0 E0 E0 [SEP] C1 E3 E1 E1 + C11 E2 E2 E1 + C26 E2 E0 E3 + C21 E0 E1 E4 + C28 E3 E1 E0 + C10 E2 E2 E0 + C15 E1 E3 E0 + C10 E0 E4 E0 + C20 E2 E1 E1 + C28 E1 E2 E1 + C30 E2 E0 E2 + C10 E1 E1 E2 + C19 E0 E2 E2 + C19 E1 E0 E3 + C7 E0 E1 E3 + C13 E3 E0 E0 + C7 E2 E1 E0 + C23 E1 E2 E0 + C23 E0 E3 E0 + C20 E2 E0 E1 + C5 E1 E1 E1 + C27 E0 E2 E1 + C2 E1 E0 E2 + C10 E0 E1 E2 + C16 E0 E0 E3 + C8 E2 E0 E0 + C30 E1 E1 E0 + C1 E0 E2 E0 + C16 E1 E0 E1 + C11 E0 E1 E1 + C30 E0 E0 E2 + C10 E1 E0 E0 + C27 E0 E1 E0 + C30 E0 E0 E1 + C13 E0 E0 E0 [SEP] C1 E4 E0 E1 + C27 E3 E1 E1 + C20 E2 E0 E3 + C29 E0 E2 E3 + C1 E3 E1 E0 + C11 E2 E2 E0 + C21 E1 E3 E0 + C22 E0 E4 E0 + C5 E3 E0 E1 + C23 E2 E1 E1 + C12 E1 E2 E1 + C4 E2 E0 E2 + C18 E1 E1 E2 + C22 E1 E0 E3 + C26 E0 E1 E3 + C26 E3 E0 E0 + C28 E2 E1 E0 + C2 E1 E2 E0 + C24 E0 E3 E0 + C19 E2 E0 E1 + C11 E1 E1 E1 + C26 E0 E2 E1 + C8 E1 E0 E2 + C15 E0 E1 E2 + C4 E0 E0 E3 + C28 E2 E0 E0 + C12 E1 E1 E0 + C11 E0 E2 E0 + C22 E1 E0 E1 + C19 E0 E1 E1 + C16 E0 E0 E2 + C28 E1 E0 E0 + C10 E0 E1 E0 + C17 E0 E0 E1 + C7 E0 E0 E0 [SEP] C1 E2 E2 E1 + C24 E0 E3 E2 + C14 E3 E1 E0 + C12 E2 E2 E0 + C26 E1 E2 E1 + C9 E0 E3 E1 + C23 E1 E1 E2 + C27 E3 E0 E0 + C8 E2 E1 E0 + C12 E1 E2 E0 + C2 E0 E3 E0 + C26 E2 E0 E1 + C26 E1 E1 E1 + C7 E0 E2 E1 + C15 E1 E0 E2 + C23 E0 E1 E2 + C8 E2 E0 E0 + C26 E1 E1 E0 + C8 E0 E2 E0 + C18 E1 E0 E1 + C22 E0 E1 E1 + C27 E0 E0 E2 + C4 E1 E0 E0 + C27 E0 E1 E0 + C2 E0 E0 E1 + C2 E0 E0 E0 [SEP] C1 E3 E1 E0 + C12 E3 E0 E1 + C18 E2 E1 E0 + C25 E0 E1 E2 + C25 E2 E0 E0 + C15 E1 E1 E0 + C14 E0 E2 E0 + C30 E1 E0 E1 + C10 E0 E1 E1 + C8 E0 E0 E2 + C8 E1 E0 E0 + C1 E0 E1 E0 + C17 E0 E0 E1 + C16 E0 E0 E0 [SEP] C1 E3 E0 E1 + C12 E2 E1 E1 + C16 E1 E2 E1 + C18 E0 E3 E1 + C19 E3 E0 E0 + C29 E2 E1 E0 + C1 E1 E2 E0 + C1 E0 E3 E0 + C15 E2 E0 E1 + C30 E1 E1 E1 + C27 E0 E2 E1 + C19 E0 E1 E2 + C24 E2 E0 E0 + C19 E1 E1 E0 + C15 E0 E2 E0 + C23 E0 E1 E1 + C11 E0 E0 E2 + C8 E1 E0 E0 + C25 E0 E1 E0 + C10 E0 E0 E1 + C27 E0 E0 E0 [SEP] C1 E0 E3 E2 + C29 E3 E1 E0 + C19 E2 E2 E0 + C30 E1 E3 E0 + C26 E0 E4 E0 + C17 E2 E1 E1 + C5 E1 E2 E1 + C6 E0 E3 E1 + C5 E2 E0 E2 + C21 E1 E1 E2 + C22 E0 E2 E2 + C27 E1 E0 E3 + C19 E0 E1 E3 + C22 E0 E0 E4 + C21 E3 E0 E0 + C19 E2 E1 E0 + C22 E1 E2 E0 + C19 E0 E3 E0 + C20 E2 E0 E1 + C19 E1 E1 E1 + C27 E0 E2 E1 + C16 E1 E0 E2 + C10 E0 E1 E2 + C6 E0 E0 E3 + C5 E2 E0 E0 + C7 E1 E1 E0 + C7 E0 E2 E0 + C7 E1 E0 E1 + C28 E0 E1 E1 + C5 E0 E0 E2 + C23 E1 E0 E0 + C15 E0 E1 E0 + C18 E0 E0 E1 + C23 E0 E0 E0 [SEP] C1 E0 E1 E4 + C14 E3 E1 E0 + C23 E2 E2 E0 + C30 E1 E3 E0 + C7 E0 E4 E0 + C12 E2 E1 E1 + C7 E1 E2 E1 + C22 E0 E3 E1 + C23 E2 E0 E2 + C9 E1 E1 E2 + C8 E1 E0 E3 + C29 E0 E1 E3 + C2 E0 E0 E4 + C5 E3 E0 E0 + C13 E2 E1 E0 + C25 E1 E2 E0 + C28 E0 E3 E0 + C19 E2 E0 E1 + C16 E1 E1 E1 + C27 E0 E2 E1 + C29 E1 E0 E2 + C18 E0 E1 E2 + C15 E0 E0 E3 + C2 E2 E0 E0 + C26 E1 E1 E0 + C3 E0 E2 E0 + C17 E1 E0 E1 + C17 E0 E1 E1 + C9 E0 E0 E2 + C1 E1 E0 E0 + C18 E0 E1 E0 + C6 E0 E0 E1 + C11 E0 E0 E0 [SEP] C1 E1 E3 E0 + C5 E0 E4 E0 + C12 E3 E0 E1 + C8 E2 E1 E1 + C20 E1 E2 E1 + C3 E0 E3 E1 + C13 E2 E0 E2 + C28 E1 E1 E2 + C9 E0 E2 E2 + C4 E1 E0 E3 + C23 E0 E1 E3 + C9 E0 E0 E4 + C19 E3 E0 E0 + C8 E1 E2 E0 + C24 E0 E3 E0 + C13 E1 E1 E1 + C14 E0 E2 E1 + C7 E1 E0 E2 + C7 E0 E1 E2 + C25 E0 E0 E3 + C16 E2 E0 E0 + C19 E1 E1 E0 + C28 E0 E2 E0 + C19 E1 E0 E1 + C16 E0 E1 E1 + C4 E0 E0 E2 + C24 E1 E0 E0 + C6 E0 E1 E0 + C13 E0 E0 E1 + C30 E0 E0 E0 [SEP] C1 E2 E0 E3 + C2 E0 E1 E4 + C11 E4 E0 E0 + C23 E3 E1 E0 + C21 E2 E2 E0 + C30 E1 E3 E0 + C14 E0 E4 E0 + C1 E3 E0 E1 + C13 E2 E1 E1 + C17 E1 E2 E1 + C13 E0 E3 E1 + C9 E2 E0 E2 + C23 E1 E1 E2 + C28 E0 E2 E2 + C9 E1 E0 E3 + C6 E0 E1 E3 + C4 E0 E0 E4 + C2 E3 E0 E0 + C10 E2 E1 E0 + C1 E1 E2 E0 + C25 E0 E3 E0 + C9 E2 E0 E1 + C21 E1 E1 E1 + C24 E0 E2 E1 + C25 E0 E1 E2 + C21 E0 E0 E3 + C19 E2 E0 E0 + C13 E1 E1 E0 + C10 E0 E2 E0 + C28 E1 E0 E1 + C7 E0 E1 E1 + C25 E0 E0 E2 + C6 E1 E0 E0 + C29 E0 E1 E0 + C9 E0 E0 E1 + C15 E0 E0 E0 [SEP] C1 E0 E2 E3 + C20 E0 E1 E4 + C5 E4 E0 E0 + C30 E3 E1 E0 + C4 E2 E2 E0 + C16 E1 E3 E0 + C29 E0 E4 E0 + C6 E3 E0 E1 + C20 E2 E1 E1 + C13 E1 E2 E1 + C10 E0 E3 E1 + C13 E2 E0 E2 + C11 E1 E1 E2 + C11 E0 E2 E2 + C30 E1 E0 E3 + C24 E0 E1 E3 + C15 E0 E0 E4 + C22 E3 E0 E0 + C15 E2 E1 E0 + C24 E1 E2 E0 + C18 E0 E3 E0 + C27 E2 E0 E1 + C22 E1 E1 E1 + C26 E0 E2 E1 + C9 E1 E0 E2 + C15 E0 E1 E2 + C18 E0 E0 E3 + C30 E2 E0 E0 + C6 E1 E1 E0 + C5 E0 E2 E0 + C24 E1 E0 E1 + C7 E0 E1 E1 + C25 E0 E0 E2 + C17 E1 E0 E0 + C30 E0 E1 E0 + C11 E0 E0 E1 + C21 E0 E0 E0 [SEP] C1 E4 E0 E0 + C29 E2 E2 E0 + C22 E1 E3 E0 + C24 E0 E4 E0 + C17 E3 E0 E1 + C8 E2 E1 E1 + C13 E1 E2 E1 + C20 E0 E3 E1 + C13 E2 E0 E2 + C11 E1 E1 E2 + C27 E0 E2 E2 + C27 E1 E0 E3 + C19 E0 E1 E3 + C22 E0 E0 E4 + C25 E3 E0 E0 + C10 E2 E1 E0 + C24 E1 E2 E0 + C12 E0 E3 E0 + C27 E2 E0 E1 + C22 E1 E1 E1 + C22 E0 E2 E1 + C23 E1 E0 E2 + C25 E0 E1 E2 + C6 E0 E0 E3 + C28 E2 E0 E0 + C2 E1 E1 E0 + C18 E0 E2 E0 + C23 E1 E0 E1 + C14 E0 E1 E1 + C7 E1 E0 E0 + C24 E0 E1 E0 + C5 E0 E0 E1 + C10 E0 E0 E0 [SEP] C1 E0 E4 E0 + C10 E3 E0 E1 + C26 E2 E1 E1 + C30 E1 E2 E1 + C26 E0 E3 E1 + C30 E2 E0 E2 + C28 E1 E1 E2 + C13 E0 E2 E2 + C27 E1 E0 E3 + C22 E0 E1 E3 + C23 E0 E0 E4 + C11 E3 E0 E0 + C22 E2 E1 E0 + C8 E1 E2 E0 + C29 E0 E3 E0 + C3 E2 E0 E1 + C17 E1 E1 E1 + C6 E0 E2 E1 + C15 E1 E0 E2 + C1 E0 E1 E2 + C22 E0 E0 E3 + C11 E2 E0 E0 + C15 E1 E1 E0 + C13 E0 E2 E0 + C13 E1 E0 E1 + C7 E0 E0 E2 + C18 E1 E0 E0 + C5 E0 E1 E0 + C25 E0 E0 E1 + C10 E0 E0 E0 [SEP] C1 E2 E1 E1 + C5 E1 E2 E1 + C12 E0 E3 E1 + C6 E2 E0 E2 + C9 E1 E1 E2 + C30 E0 E2 E2 + C23 E1 E0 E3 + C21 E0 E1 E3 + C22 E0 E0 E4 + C23 E3 E0 E0 + C21 E1 E2 E0 + C18 E0 E3 E0 + C17 E2 E0 E1 + C3 E1 E1 E1 + C6 E0 E2 E1 + C12 E1 E0 E2 + C24 E0 E1 E2 + C21 E0 E0 E3 + C30 E2 E0 E0 + C25 E1 E1 E0 + C18 E0 E2 E0 + C26 E1 E0 E1 + C11 E0 E1 E1 + C6 E0 E0 E2 + C6 E1 E0 E0 + C16 E0 E1 E0 + C19 E0 E0 E1 + C24 E0 E0 E0 [SEP] C1 E0 E3 E1 + C22 E2 E0 E2 + C11 E1 E1 E2 + C4 E0 E2 E2 + C22 E1 E0 E3 + C4 E0 E1 E3 + C25 E0 E0 E4 + C17 E3 E0 E0 + C10 E2 E1 E0 + C3 E1 E2 E0 + C8 E0 E3 E0 + C12 E2 E0 E1 + C22 E1 E1 E1 + C9 E0 E2 E1 + C28 E1 E0 E2 + C14 E0 E1 E2 + C23 E0 E0 E3 + C23 E2 E0 E0 + C2 E1 E1 E0 + C30 E0 E2 E0 + C10 E1 E0 E1 + C30 E0 E1 E1 + C12 E0 E0 E2 + C19 E1 E0 E0 + C9 E0 E1 E0 + C11 E0 E0 E1 + C22 E0 E0 E0 [SEP] C1 E2 E0 E2 + C17 E1 E1 E2 + C17 E1 E0 E3 + C11 E0 E1 E3 + C25 E0 E0 E4 + C19 E3 E0 E0 + C30 E2 E1 E0 + C1 E1 E2 E0 + C1 E0 E3 E0 + C22 E2 E0 E1 + C1 E1 E1 E1 + C7 E0 E2 E1 + C17 E1 E0 E2 + C1 E0 E1 E2 + C27 E0 E0 E3 + C7 E2 E0 E0 + C25 E1 E1 E0 + C27 E0 E2 E0 + C22 E1 E0 E1 + C22 E0 E1 E1 + C26 E0 E0 E2 + C27 E1 E0 E0 + C1 E0 E1 E0 + C19 E0 E0 E1 + C26 E0 E0 E0 [SEP] C1 E1 E1 E2 + C14 E0 E2 E2 + C14 E1 E0 E3 + C12 E0 E1 E3 + C22 E0 E0 E4 + C20 E3 E0 E0 + C9 E2 E1 E0 + C6 E1 E2 E0 + C25 E0 E3 E0 + C28 E2 E0 E1 + C2 E1 E1 E1 + C2 E0 E2 E1 + C9 E1 E0 E2 + C29 E0 E1 E2 + C3 E0 E0 E3 + C17 E2 E0 E0 + C16 E1 E1 E0 + C3 E0 E2 E0 + C5 E0 E1 E1 + C7 E1 E0 E0 + C28 E0 E1 E0 + C24 E0 E0 E1 + C2 E0 E0 E0 [SEP] C1 E0 E2 E2 + C20 E1 E0 E3 + C18 E0 E1 E3 + C3 E0 E0 E4 + C13 E2 E1 E0 + C9 E1 E2 E0 + C5 E0 E3 E0 + C20 E0 E2 E1 + C13 E1 E0 E2 + C11 E0 E1 E2 + C30 E0 E0 E3 + C1 E1 E1 E0 + C7 E0 E2 E0 + C28 E1 E0 E1 + C26 E0 E1 E1 + C15 E0 E0 E2 + C4 E1 E0 E0 + C5 E0 E1 E0 + C1 E0 E0 E1 + C18 E0 E0 E0 [SEP] C1 E0 E1 E3 + C13 E0 E0 E4 + C15 E3 E0 E0 + C2 E2 E1 E0 + C15 E1 E2 E0 + C4 E0 E3 E0 + C7 E2 E0 E1 + C5 E1 E1 E1 + C10 E0 E2 E1 + C12 E1 E0 E2 + C20 E0 E1 E2 + C3 E0 E0 E3 + C6 E2 E0 E0 + C30 E1 E1 E0 + C15 E0 E2 E0 + C26 E1 E0 E1 + C22 E0 E1 E1 + C27 E0 E0 E2 + C16 E1 E0 E0 + C2 E0 E1 E0 + C6 E0 E0 E1 + C3 E0 E0 E0 [SEP] C1 E1 E0 E3 + C26 E0 E1 E3 + C23 E0 E0 E4 + C27 E3 E0 E0 + C2 E2 E1 E0 + C18 E1 E2 E0 + C30 E0 E3 E0 + C15 E2 E0 E1 + C16 E1 E1 E1 + C6 E0 E2 E1 + C13 E1 E0 E2 + C17 E0 E1 E2 + C24 E2 E0 E0 + C15 E1 E1 E0 + C8 E0 E2 E0 + C30 E1 E0 E1 + C19 E0 E1 E1 + C30 E0 E0 E2 + C21 E1 E0 E0 + C24 E0 E1 E0 + C28 E0 E0 E1 + C14 E0 E0 E0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Namespace' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[354], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_format\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubprocessors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MonomialProcessorPlus\n\u001b[0;32m----> 3\u001b[0m mpp \u001b[38;5;241m=\u001b[39m MonomialProcessorPlus(num_variables\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mring\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_variables\u001b[39m\u001b[38;5;124m'\u001b[39m], max_degree\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolynomial\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_degree\u001b[39m\u001b[38;5;124m'\u001b[39m], max_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      6\u001b[0m input_texts \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m test_dataset]\n\u001b[1;32m      7\u001b[0m processed_input_text \u001b[38;5;241m=\u001b[39m mpp(input_texts)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Namespace' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from src.loader.data_format.processors.subprocessors import MonomialProcessorPlus\n",
    "\n",
    "mpp = MonomialProcessorPlus(num_variables=config['ring']['num_variables'], max_degree=config['polynomial']['max_degree'], max_coef=100)\n",
    "\n",
    "\n",
    "input_texts = [sample['input'] for sample in test_dataset]\n",
    "processed_input_text = mpp(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E0 E0 + C24 E0 E1 E0 + C28 E0 E0 E1 + C14 E0 E0 E0'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_input_text)\n",
    "sum([len(tt) for tt in processed_input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text.count('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Ls_input[0] - input_text.count('+')) // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for test in input_text.split(' [BIGSEP]'):\n",
    "    for test2 in test.split(' [SEP] '):\n",
    "        counter += len(test2.split(' + '))\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve SageMath objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.all import *\n",
    "from src.dataset.processors.utils import sequence_to_poly, poly_to_sequence, get_field\n",
    "\n",
    "field_name = f\"{config['field']['type']}{config['field']['param']}\"\n",
    "field = get_field(field_name)\n",
    "# ring = PolynomialRing(field, ['x', 'y', 'z'], order='degrevlex')\n",
    "ring = PolynomialRing(field, 'x', config['ring']['num_variables'], order='degrevlex')\n",
    "\n",
    "F = [sequence_to_poly(f_text, ring) for f_text in input_text.split(' [SEP] ')]\n",
    "BB = [sequence_to_poly(g_text, ring) for g_text in target_text.split(' [SEP] ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{x2: 29, x1: 15, x0: 8}, {x2: 26, x1: 10, x0: 28}, {x2: 14, x1: 22, x0: 30}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal(BB).variety()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal(BB) == ideal(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run border basis calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 121 ms, sys: 0 ns, total: 121 ms\n",
      "Wall time: 120 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[x0^2*x2^2,\n",
       "  x1*x2^4,\n",
       "  x0^3*x1*x2,\n",
       "  x0*x1^2*x2^3,\n",
       "  x1^4*x2^2,\n",
       "  x0*x1^3*x2^2,\n",
       "  x1^5*x2,\n",
       "  x0*x1^4*x2,\n",
       "  x0^2*x1^3*x2,\n",
       "  x1^6,\n",
       "  x0^3*x1^3],\n",
       " [x1^6 - 10*x0^2*x1^3*x2 - 9*x0*x1^4*x2 + 8*x1^5*x2 + 15*x0*x1^3*x2^2 + 10*x1^4*x2^2 + x0*x1^4 + 14*x1^5 + 4*x0*x1^3*x2 + 10*x1^4*x2 + 12*x0*x1^2*x2^2 - 5*x1^3*x2^2 - 9*x0*x1*x2^3 + 14*x1^2*x2^3 + 2*x1*x2^4 - 7*x0*x1^3 - 6*x1^4 + 11*x0^2*x1*x2 - 10*x0*x1^2*x2 - 5*x1^3*x2 - 6*x0*x1*x2^2 + 4*x1^2*x2^2 - 8*x1*x2^3 - 15*x0^2*x1 + 13*x0*x1^2 + 14*x1^3 - 15*x0^2*x2 - 9*x0*x1*x2 - 10*x1^2*x2 + 9*x0*x2^2 - 10*x1*x2^2 - 6*x2^3 + 6*x0*x1 - 13*x1^2 - 15*x0*x2 + 12*x1*x2 - 11*x0 - 3*x1 + 7*x2 + 13,\n",
       "  x0^3*x1^2 + 7*x0*x1^4 - 2*x0*x1^3*x2 + 14*x1^2*x2^3 + 15*x0^3*x1 - 11*x0*x1^3 - 4*x1^4 - 15*x0^3*x2 - 12*x0*x1^2*x2 + 8*x1^3*x2 + 6*x1^2*x2^2 - 15*x0^3 + 14*x0^2*x1 + 6*x0*x1^2 - 5*x1^3 - 2*x0*x1*x2 - 14*x1^2*x2 - 11*x1*x2^2 + 3*x0^2 + 13*x0*x1 - x1^2 - 7*x1*x2 + 7*x2^2 + 5*x0 - x1 + 7*x2 + 7,\n",
       "  x0^2*x1^3*x2 - 3*x0*x1^4*x2 + 13*x1^5*x2 + 5*x0*x1^3*x2^2 - 11*x1^4*x2^2 - 6*x0*x1^2*x2^3 - 2*x0^3*x1^2 - 10*x0*x1^4 + 10*x1^5 + 2*x0^3*x1*x2 - 11*x0^2*x1^2*x2 - 9*x0*x1^3*x2 + 9*x1^4*x2 - 13*x0*x1^2*x2^2 - 12*x1^3*x2^2 - 3*x0*x1*x2^3 + 15*x1^2*x2^3 + 11*x1*x2^4 + 7*x0^2*x1^2 - 11*x0*x1^3 - 8*x1^4 + 7*x0^2*x1*x2 - 15*x0*x1^2*x2 - 15*x0*x1*x2^2 + 14*x1^2*x2^2 - 13*x1*x2^3 + 9*x0^2*x1 + 4*x0*x1^2 + 8*x1^3 - 10*x0^2*x2 + 9*x0*x1*x2 + 10*x1^2*x2 + 3*x0*x2^2 + 15*x1*x2^2 - 2*x2^3 + 11*x0^2 - 13*x0*x1 + 13*x0*x2 + 8*x1*x2 + 10*x2^2 + 12*x0 + 7*x1 + 13*x2 - 5,\n",
       "  x0^2*x1^2*x2 + 2*x0^2*x1^2 - x0*x1^3 + 5*x1^4 - 8*x0^2*x1*x2 + 11*x0*x1^2*x2 + 8*x1^3*x2 + 8*x0^2*x2^2 - 3*x1^2*x2^2 + 14*x0^2*x1 - 15*x0*x1^2 + 10*x1^3 + 8*x0^2*x2 + 14*x1^2*x2 - 2*x0*x1 + 9*x1^2 - 12*x0*x2 - 12*x1*x2 + 8*x0 + 2*x1 - 8*x2 - 13,\n",
       "  x0*x1^4 + 2*x0^3*x1*x2 + 10*x0*x1^3*x2 - 9*x1^2*x2^3 - 2*x1*x2^4 - 11*x0^3*x1 - 4*x0^2*x1^2 - 4*x0*x1^3 + 11*x1^4 + 3*x0^3*x2 - 10*x0*x1^2*x2 - 13*x1^3*x2 + 5*x1^2*x2^2 + 8*x1*x2^3 - 3*x0^3 - 10*x0^2*x1 + 10*x0*x1^2 - 11*x1^3 + 12*x0^2*x2 + 7*x0*x1*x2 + 9*x1^2*x2 - 4*x1*x2^2 + 6*x2^3 - 12*x0^2 + 12*x0*x1 - 5*x1^2 + 11*x1*x2 + 11*x2^2 + 8*x0 - 5*x1 + 11*x2 - 6,\n",
       "  x0^2*x1^3 - 15*x1^4*x2 - 12*x0*x1*x2^3 + 15*x0^2*x1^2 - 2*x1^4 + x0*x1^2*x2 + x1^3*x2 - 14*x0*x1*x2^2 + 8*x1^2*x2^2 - 5*x1*x2^3 + 4*x0^2*x1 - 7*x1^3 - 9*x0*x1*x2 - x1^2*x2 + 5*x0*x2^2 - 5*x1*x2^2 - 14*x0^2 - 3*x0*x1 + 10*x1^2 - 5*x0*x2 + 13*x1*x2 + 15*x2^2 + 14*x0 + 12*x1 - 3*x2 + 2,\n",
       "  x0^3*x1^3 - 7*x0^2*x1^3*x2 + 14*x0*x1^2*x2^3 + 9*x0^2*x1^3 - 11*x0*x1^4 - 14*x0*x1^3*x2 + 13*x1^2*x2^3 - 9*x0^2*x1^2 - 10*x0*x1^3 + 12*x0^2*x1*x2 - 15*x0*x1^2*x2 + 10*x1^3*x2 - 4*x1^2*x2^2 + 5*x1*x2^3 - 6*x0^3 - 13*x0*x1^2 + 13*x1^3 - 8*x0*x1*x2 + 10*x1^2*x2 - 6*x1*x2^2 + 5*x2^3 - x0^2 - 12*x0*x1 + 13*x1^2 - 7*x0*x2 - 4*x1*x2 + 8*x2^2 - 14*x0 + 15*x1 - 2*x2 - 7,\n",
       "  x0*x1^3 + 5*x0*x1^2 + 11*x1^3 - 9*x1^2*x2 - x0*x1 - 5*x1^2 + 14*x0*x2 + 8*x1*x2 - x2^2 - 13*x0 - 2*x1 - 6*x2 - 10],\n",
       " [x0^3*x1^2*x2 + 2*x0^3*x1^2 - x0^2*x1^3 + 5*x0*x1^4 - 8*x0^3*x1*x2 + 11*x0^2*x1^2*x2 + 8*x0*x1^3*x2 + 8*x0^3*x2^2 - 3*x0*x1^2*x2^2 + 14*x0^3*x1 - 15*x0^2*x1^2 + 10*x0*x1^3 + 8*x0^3*x2 + 14*x0*x1^2*x2 - 2*x0^2*x1 + 9*x0*x1^2 - 12*x0^2*x2 - 12*x0*x1*x2 + 8*x0^2 + 2*x0*x1 - 8*x0*x2 - 13*x0,\n",
       "  x0^2*x1^3*x2 + 2*x0^2*x1^3 - x0*x1^4 + 5*x1^5 - 8*x0^2*x1^2*x2 + 11*x0*x1^3*x2 + 8*x1^4*x2 + 8*x0^2*x1*x2^2 - 3*x1^3*x2^2 + 14*x0^2*x1^2 - 15*x0*x1^3 + 10*x1^4 + 8*x0^2*x1*x2 + 14*x1^3*x2 - 2*x0*x1^2 + 9*x1^3 - 12*x0*x1*x2 - 12*x1^2*x2 + 8*x0*x1 + 2*x1^2 - 8*x1*x2 - 13*x1,\n",
       "  x0*x1^5 + 2*x0^3*x1^2*x2 + 10*x0*x1^4*x2 - 9*x1^3*x2^3 - 2*x1^2*x2^4 - 11*x0^3*x1^2 - 4*x0^2*x1^3 - 4*x0*x1^4 + 11*x1^5 + 3*x0^3*x1*x2 - 10*x0*x1^3*x2 - 13*x1^4*x2 + 5*x1^3*x2^2 + 8*x1^2*x2^3 - 3*x0^3*x1 - 10*x0^2*x1^2 + 10*x0*x1^3 - 11*x1^4 + 12*x0^2*x1*x2 + 7*x0*x1^2*x2 + 9*x1^3*x2 - 4*x1^2*x2^2 + 6*x1*x2^3 - 12*x0^2*x1 + 12*x0*x1^2 - 5*x1^3 + 11*x1^2*x2 + 11*x1*x2^2 + 8*x0*x1 - 5*x1^2 + 11*x1*x2 - 6*x1,\n",
       "  x0^2*x1^3*x2 - 15*x1^4*x2^2 - 12*x0*x1*x2^4 + 15*x0^2*x1^2*x2 - 2*x1^4*x2 + x0*x1^2*x2^2 + x1^3*x2^2 - 14*x0*x1*x2^3 + 8*x1^2*x2^3 - 5*x1*x2^4 + 4*x0^2*x1*x2 - 7*x1^3*x2 - 9*x0*x1*x2^2 - x1^2*x2^2 + 5*x0*x2^3 - 5*x1*x2^3 - 14*x0^2*x2 - 3*x0*x1*x2 + 10*x1^2*x2 - 5*x0*x2^2 + 13*x1*x2^2 + 15*x2^3 + 14*x0*x2 + 12*x1*x2 - 3*x2^2 + 2*x2,\n",
       "  x0^2*x1^3 + 5*x0^2*x1^2 + 11*x0*x1^3 - 9*x0*x1^2*x2 - x0^2*x1 - 5*x0*x1^2 + 14*x0^2*x2 + 8*x0*x1*x2 - x0*x2^2 - 13*x0^2 - 2*x0*x1 - 6*x0*x2 - 10*x0,\n",
       "  x0*x1^4 + 5*x0*x1^3 + 11*x1^4 - 9*x1^3*x2 - x0*x1^2 - 5*x1^3 + 14*x0*x1*x2 + 8*x1^2*x2 - x1*x2^2 - 13*x0*x1 - 2*x1^2 - 6*x1*x2 - 10*x1,\n",
       "  x0*x1^3*x2 + 5*x0*x1^2*x2 + 11*x1^3*x2 - 9*x1^2*x2^2 - x0*x1*x2 - 5*x1^2*x2 + 14*x0*x2^2 + 8*x1*x2^2 - x2^3 - 13*x0*x2 - 2*x1*x2 - 6*x2^2 - 10*x2]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from src.border_basis_lib.improved_border_basis import ImprovedBorderBasisCalculator\n",
    "\n",
    "calculator = ImprovedBorderBasisCalculator(ring, corollary_23=True, N=100, save_universes=True, verbose=False)\n",
    "\n",
    "use_fast_elimination = True  # use gaussian_elimination_fast\n",
    "lstabilization_only = False  # only compute L-stable span\n",
    "\n",
    "G, O, _ = calculator.compute_border_basis_optimized(F,\n",
    "                                            use_fast_elimination=use_fast_elimination,\n",
    "                                            lstabilization_only=lstabilization_only)\n",
    "\n",
    "calculator.datasets[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get expantion dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C16 E0 E6 E0 + C26 E2 E3 E1 + C11 E1 E4 E1 + C4 E0 E5 E1 + C23 E1 E3 E2 + C5 E0 E4 E2 + C16 E1 E4 E0 + C7 E0 E5 E0 + C2 E1 E3 E1 + C5 E0 E4 E1 + C6 E1 E2 E2 + C13 E0 E3 E2 + C11 E1 E1 E3 + C7 E0 E2 E3 + C1 E0 E1 E4 + C12 E1 E3 E0 + C28 E0 E4 E0 + C21 E2 E1 E1 + C26 E1 E2 E1 + C13 E0 E3 E1 + C28 E1 E1 E2 + C2 E0 E2 E2 + C27 E0 E1 E3 + C8 E2 E1 E0 + C22 E1 E2 E0 + C7 E0 E3 E0 + C8 E2 E0 E1 + C11 E1 E1 E1 + C26 E0 E2 E1 + C20 E1 E0 E2 + C26 E0 E1 E2 + C28 E0 E0 E3 + C3 E1 E1 E0 + C9 E0 E2 E0 + C8 E1 E0 E1 + C6 E0 E1 E1 + C10 E1 E0 E0 + C14 E0 E1 E0 + C19 E0 E0 E1 + C22 E0 E0 E0 [SEP] C20 E3 E2 E0 + C16 E1 E4 E0 + C22 E1 E3 E1 + C1 E0 E2 E3 + C21 E3 E1 E0 + C28 E1 E3 E0 + C13 E0 E4 E0 + C10 E3 E0 E1 + C8 E1 E2 E1 + C5 E0 E3 E1 + C27 E0 E2 E2 + C10 E3 E0 E0 + C1 E2 E1 E0 + C27 E1 E2 E0 + C24 E0 E3 E0 + C22 E1 E1 E1 + C30 E0 E2 E1 + C28 E0 E1 E2 + C29 E2 E0 E0 + C12 E1 E1 E0 + C11 E0 E2 E0 + C15 E0 E1 E1 + C16 E0 E0 E2 + C7 E1 E0 E0 + C11 E0 E1 E0 + C16 E0 E0 E1 + C16 E0 E0 E0 [SEP] C11 E0 E6 E0 + C12 E2 E3 E1 + C8 E0 E4 E2 + C12 E1 E2 E3 + C4 E3 E2 E0 + C10 E0 E5 E0 + C27 E3 E1 E1 + C22 E2 E2 E1 + C30 E0 E4 E1 + C3 E1 E2 E2 + C17 E2 E2 E0 + C7 E1 E3 E0 + C12 E0 E4 E0 + C14 E2 E1 E1 + C13 E1 E2 E1 + C7 E0 E3 E1 + C26 E1 E1 E2 + C16 E0 E2 E2 + C3 E2 E1 E0 + C11 E1 E2 E0 + C14 E0 E3 E0 + C10 E2 E0 E1 + C7 E1 E1 E1 + C25 E0 E2 E1 + C15 E0 E1 E2 + C9 E2 E0 E0 + C30 E1 E1 E0 + C12 E0 E2 E0 + C26 E1 E0 E1 + C23 E0 E1 E1 + C11 E0 E0 E2 + C10 E1 E0 E0 + C15 E0 E1 E0 + C20 E0 E0 E1 + C29 E0 E0 E0 [SEP] C8 E2 E2 E1 + C16 E2 E2 E0 + C23 E1 E3 E0 + C9 E0 E4 E0 + C29 E2 E1 E1 + C26 E1 E2 E1 + C2 E0 E3 E1 + C2 E2 E0 E2 + C7 E0 E2 E2 + C19 E2 E1 E0 + C4 E1 E2 E0 + C18 E0 E3 E0 + C2 E2 E0 E1 + C19 E0 E2 E1 + C15 E1 E1 E0 + C10 E0 E2 E0 + C28 E1 E0 E1 + C28 E0 E1 E1 + C2 E1 E0 E0 + C16 E0 E1 E0 + C29 E0 E0 E1 + C20 E0 E0 E0 [SEP] C10 E3 E2 E0 + C27 E1 E4 E0 + C7 E3 E1 E1 + C15 E1 E3 E1 + C24 E0 E1 E4 + C3 E3 E1 E0 + C17 E2 E2 E0 + C14 E0 E4 E0 + C19 E0 E3 E1 + C28 E0 E1 E3 + C10 E3 E0 E0 + C12 E2 E1 E0 + C2 E1 E2 E0 + C20 E0 E3 E0 + C11 E2 E0 E1 + C20 E1 E1 E1 + C21 E0 E0 E3 + C19 E2 E0 E0 + C17 E1 E1 E0 + C19 E0 E2 E0 + C15 E0 E1 E1 + C16 E1 E0 E0 + C19 E0 E1 E0 + C18 E0 E0 E0 [SEP] C8 E2 E3 E0 + C4 E0 E4 E1 + C28 E1 E1 E3 + C27 E2 E2 E0 + C15 E0 E4 E0 + C8 E1 E2 E1 + C8 E0 E3 E1 + C12 E1 E1 E2 + C2 E0 E2 E2 + C22 E0 E1 E3 + C1 E2 E1 E0 + C6 E0 E3 E0 + C21 E1 E1 E1 + C23 E0 E2 E1 + C9 E1 E0 E2 + C22 E0 E1 E2 + C12 E2 E0 E0 + C7 E1 E1 E0 + C18 E0 E2 E0 + C22 E1 E0 E1 + C11 E0 E1 E1 + C27 E0 E0 E2 + C19 E1 E0 E0 + C3 E0 E1 E0 + C7 E0 E0 E1 + C16 E0 E0 E0 [SEP] C20 E3 E3 E0 + C15 E2 E3 E1 + C1 E1 E2 E3 + C25 E2 E3 E0 + C28 E1 E4 E0 + C30 E1 E3 E1 + C12 E0 E2 E3 + C6 E2 E2 E0 + C17 E1 E3 E0 + C23 E2 E1 E1 + C10 E1 E2 E1 + C14 E0 E3 E1 + C13 E0 E2 E2 + C7 E0 E1 E3 + C4 E3 E0 E0 + C19 E1 E2 E0 + C12 E0 E3 E0 + C26 E1 E1 E1 + C14 E0 E2 E1 + C4 E0 E1 E2 + C7 E0 E0 E3 + C11 E2 E0 E0 + C8 E1 E1 E0 + C12 E0 E2 E0 + C15 E1 E0 E1 + C13 E0 E1 E1 + C5 E0 E0 E2 + C30 E1 E0 E0 + C21 E0 E1 E0 + C22 E0 E0 E1 + C15 E0 E0 E0 [SEP] C7 E1 E3 E0 + C4 E1 E2 E0 + C15 E0 E3 E0 + C30 E0 E2 E1 + C24 E1 E1 E0 + C27 E0 E2 E0 + C5 E1 E0 E1 + C25 E0 E1 E1 + C24 E0 E0 E2 + C2 E1 E0 E0 + C17 E0 E1 E0 + C20 E0 E0 E1 + C23 E0 E0 E0 [SEP] C1 E2 E0 E2 [SEP] C1 E0 E1 E4 [SEP] C1 E3 E1 E1 [SEP] C1 E1 E2 E3 [SEP] C1 E0 E4 E2 [SEP] C1 E1 E3 E2 [SEP] C1 E0 E5 E1 [SEP] C1 E1 E4 E1 [SEP] C1 E2 E3 E1 [SEP] C1 E0 E6 E0 [SEP] C1 E3 E3 E0 [SEP] C1 E0 E6 E0 + C21 E2 E3 E1 + C22 E1 E4 E1 + C8 E0 E5 E1 + C15 E1 E3 E2 + C10 E0 E4 E2 + C1 E1 E4 E0 + C14 E0 E5 E0 + C4 E1 E3 E1 + C10 E0 E4 E1 + C12 E1 E2 E2 + C26 E0 E3 E2 + C22 E1 E1 E3 + C14 E0 E2 E3 + C2 E0 E1 E4 + C24 E1 E3 E0 + C25 E0 E4 E0 + C11 E2 E1 E1 + C21 E1 E2 E1 + C26 E0 E3 E1 + C25 E1 E1 E2 + C4 E0 E2 E2 + C23 E0 E1 E3 + C16 E2 E1 E0 + C13 E1 E2 E0 + C14 E0 E3 E0 + C16 E2 E0 E1 + C22 E1 E1 E1 + C21 E0 E2 E1 + C9 E1 E0 E2 + C21 E0 E1 E2 + C25 E0 E0 E3 + C6 E1 E1 E0 + C18 E0 E2 E0 + C16 E1 E0 E1 + C12 E0 E1 E1 + C20 E1 E0 E0 + C28 E0 E1 E0 + C7 E0 E0 E1 + C13 E0 E0 E0 [SEP] C1 E3 E2 E0 + C7 E1 E4 E0 + C29 E1 E3 E1 + C14 E0 E2 E3 + C15 E3 E1 E0 + C20 E1 E3 E0 + C27 E0 E4 E0 + C16 E3 E0 E1 + C19 E1 E2 E1 + C8 E0 E3 E1 + C6 E0 E2 E2 + C16 E3 E0 E0 + C14 E2 E1 E0 + C6 E1 E2 E0 + C26 E0 E3 E0 + C29 E1 E1 E1 + C17 E0 E2 E1 + C20 E0 E1 E2 + C3 E2 E0 E0 + C13 E1 E1 E0 + C30 E0 E2 E0 + C24 E0 E1 E1 + C7 E0 E0 E2 + C5 E1 E0 E0 + C30 E0 E1 E0 + C7 E0 E0 E1 + C7 E0 E0 E0 [SEP] C1 E2 E3 E1 + C28 E1 E4 E1 + C13 E0 E5 E1 + C5 E1 E3 E2 + C20 E0 E4 E2 + C25 E1 E2 E3 + C29 E3 E2 E0 + C21 E1 E4 E0 + C10 E0 E5 E0 + C2 E3 E1 E1 + C20 E2 E2 E1 + C22 E1 E3 E1 + C9 E0 E4 E1 + C18 E1 E2 E2 + C19 E0 E3 E2 + C28 E1 E1 E3 + C15 E0 E2 E3 + C11 E0 E1 E4 + C7 E2 E2 E0 + C20 E1 E3 E0 + C23 E0 E4 E0 + C7 E2 E1 E1 + C16 E1 E2 E1 + C16 E1 E1 E2 + C14 E0 E2 E2 + C18 E0 E1 E3 + C9 E2 E1 E0 + C4 E1 E2 E0 + C8 E0 E3 E0 + C21 E2 E0 E1 + C9 E1 E1 E1 + C10 E0 E2 E1 + C3 E1 E0 E2 + C15 E0 E1 E2 + C29 E0 E0 E3 + C11 E2 E0 E0 + C18 E1 E1 E0 + C13 E1 E0 E1 + C8 E0 E1 E1 + C10 E0 E0 E2 + C12 E1 E0 E0 + C7 E0 E1 E0 + C13 E0 E0 E1 + C26 E0 E0 E0 [SEP] C1 E2 E2 E1 + C2 E2 E2 E0 + C30 E1 E3 E0 + C5 E0 E4 E0 + C23 E2 E1 E1 + C11 E1 E2 E1 + C8 E0 E3 E1 + C8 E2 E0 E2 + C28 E0 E2 E2 + C14 E2 E1 E0 + C16 E1 E2 E0 + C10 E0 E3 E0 + C8 E2 E0 E1 + C14 E0 E2 E1 + C29 E1 E1 E0 + C9 E0 E2 E0 + C19 E1 E0 E1 + C19 E0 E1 E1 + C8 E1 E0 E0 + C2 E0 E1 E0 + C23 E0 E0 E1 + C18 E0 E0 E0 [SEP] C1 E1 E4 E0 + C2 E3 E1 E1 + C10 E1 E3 E1 + C22 E0 E2 E3 + C29 E0 E1 E4 + C20 E3 E1 E0 + C27 E2 E2 E0 + C27 E1 E3 E0 + C11 E0 E4 E0 + C3 E3 E0 E1 + C21 E1 E2 E1 + C18 E0 E3 E1 + C5 E0 E2 E2 + C8 E0 E1 E3 + C28 E3 E0 E0 + C21 E2 E1 E0 + C10 E1 E2 E0 + C20 E0 E3 E0 + C12 E2 E0 E1 + C7 E1 E1 E1 + C9 E0 E2 E1 + C27 E0 E1 E2 + C6 E0 E0 E3 + C19 E2 E0 E0 + C12 E1 E1 E0 + C26 E0 E2 E0 + C11 E0 E1 E1 + C11 E0 E0 E2 + C8 E1 E0 E0 + C26 E0 E1 E0 + C11 E0 E0 E1 + C25 E0 E0 E0 [SEP] C1 E2 E3 E0 + C16 E0 E4 E1 + C19 E1 E1 E3 + C15 E2 E2 E0 + C29 E0 E4 E0 + C1 E1 E2 E1 + C1 E0 E3 E1 + C17 E1 E1 E2 + C8 E0 E2 E2 + C26 E0 E1 E3 + C4 E2 E1 E0 + C24 E0 E3 E0 + C22 E1 E1 E1 + C30 E0 E2 E1 + C5 E1 E0 E2 + C26 E0 E1 E2 + C17 E2 E0 E0 + C28 E1 E1 E0 + C10 E0 E2 E0 + C26 E1 E0 E1 + C13 E0 E1 E1 + C15 E0 E0 E2 + C14 E1 E0 E0 + C12 E0 E1 E0 + C28 E0 E0 E1 + C2 E0 E0 E0 [SEP] C1 E3 E3 E0 + C24 E2 E3 E1 + C14 E1 E2 E3 + C9 E2 E3 E0 + C20 E1 E4 E0 + C17 E1 E3 E1 + C13 E0 E2 E3 + C22 E2 E2 E0 + C21 E1 E3 E0 + C12 E2 E1 E1 + C16 E1 E2 E1 + C10 E0 E3 E1 + C27 E0 E2 E2 + C5 E0 E1 E3 + C25 E3 E0 E0 + C18 E1 E2 E0 + C13 E0 E3 E0 + C23 E1 E1 E1 + C10 E0 E2 E1 + C25 E0 E1 E2 + C5 E0 E0 E3 + C30 E2 E0 E0 + C19 E1 E1 E0 + C13 E0 E2 E0 + C24 E1 E0 E1 + C27 E0 E1 E1 + C8 E0 E0 E2 + C17 E1 E0 E0 + C15 E0 E1 E0 + C29 E0 E0 E1 + C24 E0 E0 E0 [SEP] C1 E1 E3 E0 + C5 E1 E2 E0 + C11 E0 E3 E0 + C22 E0 E2 E1 + C30 E1 E1 E0 + C26 E0 E2 E0 + C14 E1 E0 E1 + C8 E0 E1 E1 + C30 E0 E0 E2 + C18 E1 E0 E0 + C29 E0 E1 E0 + C25 E0 E0 E1 + C21 E0 E0 E0 # C1 E3 E2 E1 + C2 E3 E2 E0 + C30 E2 E3 E0 + C5 E1 E4 E0 + C23 E3 E1 E1 + C11 E2 E2 E1 + C8 E1 E3 E1 + C8 E3 E0 E2 + C28 E1 E2 E2 + C14 E3 E1 E0 + C16 E2 E2 E0 + C10 E1 E3 E0 + C8 E3 E0 E1 + C14 E1 E2 E1 + C29 E2 E1 E0 + C9 E1 E2 E0 + C19 E2 E0 E1 + C19 E1 E1 E1 + C8 E2 E0 E0 + C2 E1 E1 E0 + C23 E1 E0 E1 + C18 E1 E0 E0 [SEP] C1 E2 E3 E1 + C2 E2 E3 E0 + C30 E1 E4 E0 + C5 E0 E5 E0 + C23 E2 E2 E1 + C11 E1 E3 E1 + C8 E0 E4 E1 + C8 E2 E1 E2 + C28 E0 E3 E2 + C14 E2 E2 E0 + C16 E1 E3 E0 + C10 E0 E4 E0 + C8 E2 E1 E1 + C14 E0 E3 E1 + C29 E1 E2 E0 + C9 E0 E3 E0 + C19 E1 E1 E1 + C19 E0 E2 E1 + C8 E1 E1 E0 + C2 E0 E2 E0 + C23 E0 E1 E1 + C18 E0 E1 E0 [SEP] C1 E1 E5 E0 + C2 E3 E2 E1 + C10 E1 E4 E1 + C22 E0 E3 E3 + C29 E0 E2 E4 + C20 E3 E2 E0 + C27 E2 E3 E0 + C27 E1 E4 E0 + C11 E0 E5 E0 + C3 E3 E1 E1 + C21 E1 E3 E1 + C18 E0 E4 E1 + C5 E0 E3 E2 + C8 E0 E2 E3 + C28 E3 E1 E0 + C21 E2 E2 E0 + C10 E1 E3 E0 + C20 E0 E4 E0 + C12 E2 E1 E1 + C7 E1 E2 E1 + C9 E0 E3 E1 + C27 E0 E2 E2 + C6 E0 E1 E3 + C19 E2 E1 E0 + C12 E1 E2 E0 + C26 E0 E3 E0 + C11 E0 E2 E1 + C11 E0 E1 E2 + C8 E1 E1 E0 + C26 E0 E2 E0 + C11 E0 E1 E1 + C25 E0 E1 E0 [SEP] C1 E2 E3 E1 + C16 E0 E4 E2 + C19 E1 E1 E4 + C15 E2 E2 E1 + C29 E0 E4 E1 + C1 E1 E2 E2 + C1 E0 E3 E2 + C17 E1 E1 E3 + C8 E0 E2 E3 + C26 E0 E1 E4 + C4 E2 E1 E1 + C24 E0 E3 E1 + C22 E1 E1 E2 + C30 E0 E2 E2 + C5 E1 E0 E3 + C26 E0 E1 E3 + C17 E2 E0 E1 + C28 E1 E1 E1 + C10 E0 E2 E1 + C26 E1 E0 E2 + C13 E0 E1 E2 + C15 E0 E0 E3 + C14 E1 E0 E1 + C12 E0 E1 E1 + C28 E0 E0 E2 + C2 E0 E0 E1 [SEP] C1 E2 E3 E0 + C5 E2 E2 E0 + C11 E1 E3 E0 + C22 E1 E2 E1 + C30 E2 E1 E0 + C26 E1 E2 E0 + C14 E2 E0 E1 + C8 E1 E1 E1 + C30 E1 E0 E2 + C18 E2 E0 E0 + C29 E1 E1 E0 + C25 E1 E0 E1 + C21 E1 E0 E0 [SEP] C1 E1 E4 E0 + C5 E1 E3 E0 + C11 E0 E4 E0 + C22 E0 E3 E1 + C30 E1 E2 E0 + C26 E0 E3 E0 + C14 E1 E1 E1 + C8 E0 E2 E1 + C30 E0 E1 E2 + C18 E1 E1 E0 + C29 E0 E2 E0 + C25 E0 E1 E1 + C21 E0 E1 E0 [SEP] C1 E1 E3 E1 + C5 E1 E2 E1 + C11 E0 E3 E1 + C22 E0 E2 E2 + C30 E1 E1 E1 + C26 E0 E2 E1 + C14 E1 E0 E2 + C8 E0 E1 E2 + C30 E0 E0 E3 + C18 E1 E0 E1 + C29 E0 E1 E1 + C25 E0 E0 E2 + C21 E0 E0 E1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    calculator.datasets[0][0] gives\n",
    "    (L,  # Geneators of the order ideal O(L)\n",
    "     V,  # Target set of polynomials to span,\n",
    "     S,  # # List of polynomials that were successfully extended\n",
    "     )\n",
    "     \n",
    "     From this, we construct \n",
    "     input: \n",
    "     (F, L, V)\n",
    "     output: \n",
    "     (S)  \n",
    "     \n",
    "     Note: \n",
    "     It would be better to put something like [SUPER_SEP] instead of [SEP] between F, L, V. \n",
    "'''\n",
    "\n",
    "\n",
    "## Get one sample\n",
    "L, V, S = calculator.datasets[0][0]\n",
    "inputs = F + L + V\n",
    "target = S\n",
    "\n",
    "inputs_text = [poly_to_sequence(f) for f in inputs]\n",
    "inputs_text = ' [SEP] '.join(inputs_text)\n",
    "target_text = [poly_to_sequence(f) for f in target]\n",
    "target_text = ' [SEP] '.join(target_text)\n",
    "\n",
    "sample_text = ' # '.join([inputs_text, target_text])\n",
    "\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect all samples.\n",
    "\n",
    "number_of_Lstabspan = len(calculator.datasets)\n",
    "\n",
    "dataset = []\n",
    "for i in range(number_of_Lstabspan):\n",
    "    number_of_Lstabspan_iterations = len(calculator.datasets[i])\n",
    "    for j in range(number_of_Lstabspan_iterations):\n",
    "        L, V, S = calculator.datasets[i][j]\n",
    "        \n",
    "        inputs = F + L + V\n",
    "        target = S\n",
    "\n",
    "        inputs_text = [poly_to_sequence(f) for f in inputs]\n",
    "        inputs_text = ' [SEP] '.join(inputs_text)\n",
    "        target_text = [poly_to_sequence(f) for f in target]\n",
    "        target_text = ' [SEP] '.join(target_text)\n",
    "\n",
    "        sample_text = ' # '.join([inputs_text, target_text])\n",
    "\n",
    "        dataset.append(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ntokens = [len(sample.split()) for sample in dataset] # The number of tokens\n",
    "\n",
    "plt.hist(ntokens)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 11, V: 8, S: 7\n",
      "#tokens in L: 4.0, 0.0, 4, 4\n",
      "#tokens in V: 145.875, 45.957691140874346, 64, 219\n",
      "#tokens in S: 99.71428571428571, 34.5820526768863, 64, 159\n"
     ]
    }
   ],
   "source": [
    "L, V, S = calculator.datasets[0][0]\n",
    "\n",
    "print(f'L: {len(L)}, V: {len(V)}, S: {len(S)}')\n",
    "\n",
    "L_lengths = [] \n",
    "for l in L: \n",
    "    length = len(poly_to_sequence(l).split())\n",
    "    # print(length)\n",
    "    L_lengths.append(length)\n",
    "\n",
    "V_lengths = []\n",
    "for v in V: \n",
    "    length = len(poly_to_sequence(v).split())\n",
    "    # print(length)\n",
    "    V_lengths.append(length)\n",
    "\n",
    "S_lengths = []\n",
    "for s in S: \n",
    "    length = len(poly_to_sequence(s).split())\n",
    "    # print(length)\n",
    "    S_lengths.append(length)\n",
    "\n",
    "import numpy as np \n",
    "print(f'#tokens in L: {np.mean(L_lengths)}, {np.std(L_lengths)}, {np.min(L_lengths)}, {np.max(L_lengths)}')\n",
    "print(f'#tokens in V: {np.mean(V_lengths)}, {np.std(V_lengths)}, {np.min(V_lengths)}, {np.max(V_lengths)}')\n",
    "print(f'#tokens in S: {np.mean(S_lengths)}, {np.std(S_lengths)}, {np.min(S_lengths)}, {np.max(S_lengths)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x1^3*x2^2,\n",
       " x0*x1^2*x2^2,\n",
       " x1^4*x2,\n",
       " x0*x1^3*x2,\n",
       " x0^2*x1^2*x2,\n",
       " x0^3*x1*x2,\n",
       " x0^4*x2,\n",
       " x1^5,\n",
       " x0*x1^4,\n",
       " x0^2*x1^3,\n",
       " x0^3*x1^2,\n",
       " x0^4*x1,\n",
       " x0^5,\n",
       " x2^6,\n",
       " x1*x2^5,\n",
       " x0*x2^5,\n",
       " x1^2*x2^4,\n",
       " x0*x1*x2^4,\n",
       " x0^2*x2^4,\n",
       " x0^2*x1*x2^3,\n",
       " x0^3*x2^3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x0*x1^4 - 13*x0^4*x2 + 10*x0^3*x1*x2 - 6*x0^2*x1*x2^2 - 6*x0^2*x2^3 + 3*x1^2*x2^3 - 14*x0^4 + 10*x0^3*x1 - 10*x0^2*x1^2 - 12*x0*x1^3 - x0^3*x2 + 15*x0^2*x1*x2 - 3*x0*x1^2*x2 - 11*x1^3*x2 + 4*x0^2*x2^2 + 14*x0*x1*x2^2 + 6*x1^2*x2^2 - 9*x0*x2^3 + 10*x1*x2^3 + 4*x2^4 - x0^3 + 10*x0^2*x1 + 6*x0*x1^2 - 15*x1^3 - 6*x0^2*x2 + 6*x0*x1*x2 + 10*x1^2*x2 - 7*x0*x2^2 + 15*x2^3 + x0^2 - 13*x0*x1 + 5*x1^2 - 4*x0*x2 - 12*x1*x2 + 4*x2^2 - 7*x0 - 5*x1 + 6*x2 + 4,\n",
       " x0^2*x1^3 + 2*x0^2*x1^2*x2 - 12*x0^2*x1*x2^2 + 5*x0*x1^2*x2^2 - 15*x1^3*x2^2 - 15*x0^3*x1 - 10*x0^2*x1^2 - 9*x0*x1^3 - 12*x1^4 + x0^2*x1*x2 - 10*x0*x1^2*x2 - 3*x1^3*x2 - 9*x0*x1*x2^2 - 8*x1^2*x2^2 + 5*x0*x2^3 + 2*x1*x2^3 + x0^2*x1 - 13*x0*x1^2 - 3*x1^3 - 11*x0^2*x2 - 7*x0*x1*x2 + 12*x1^2*x2 + 14*x0*x2^2 + 8*x1*x2^2 - x2^3 + 11*x0^2 - 13*x0*x1 - x1^2 - 7*x0*x2 + 4*x1*x2 - 4*x2^2 + 12*x0 - 3*x1 - 2*x2 - 6,\n",
       " x0^2*x1^2 + 12*x0*x1^3 + 2*x0^3*x2 + 5*x0*x1^2*x2 - 3*x0^2*x2^2 - 12*x1^2*x2^2 + 9*x0*x2^3 + 4*x0^3 + 6*x0^2*x1 + 12*x0*x1^2 - 15*x1^3 + 2*x0^2*x2 - 5*x0*x1*x2 - 5*x1^2*x2 - 14*x0*x2^2 - 5*x1*x2^2 + 2*x2^3 + 15*x0*x1 + 13*x1^2 - 13*x0*x2 + 9*x1*x2 - 11*x2^2 - 6*x0 + 11*x1 + 15*x2 - 4,\n",
       " x0^3*x1*x2 - 10*x1^2*x2^3 + 4*x0^2*x1^2 + 11*x0^2*x1*x2 - 12*x0*x1^2*x2 - 13*x0*x1*x2^2 + 12*x1^2*x2^2 - 12*x0*x2^3 + 15*x1*x2^3 + 7*x0^3 - 8*x0^2*x1 + 3*x0*x1^2 + 6*x1^3 - 10*x0^2*x2 - 12*x0*x1*x2 - 5*x1^2*x2 + 6*x0*x2^2 - 11*x0^2 + 5*x0*x1 - 10*x1^2 + 7*x0*x2 + 6*x1*x2 + 10*x2^2 - 6*x0 + 6*x1 - 14*x2 - 2,\n",
       " x0^4*x1 + 11*x0^3*x1 - 5*x0^2*x1^2 + 4*x0^2*x1*x2 - 8*x0^2*x1 - 15*x0*x1^2 + 3*x0*x1*x2 + 3*x1^2*x2 - 10*x2^3 - 5*x0^2 + 15*x0*x1 + 15*x1^2 + 5*x0*x2 - x1*x2 + 14*x2^2 - 14*x0 - 5*x1 - 10*x2 + 9]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x0^2 + 11*x0 - 12*x1 - 11*x2 + 13,\n",
       " x0*x1 + 9*x0 + 8*x1 + 6*x2 - 12,\n",
       " x1^2 + 5*x0 - 12*x1 + 8*x2 + 6,\n",
       " x0*x2 + 13*x0 + 14*x1 + 12*x2 + 7,\n",
       " x1*x2 + 8*x0 + 5*x1 + x2 - 13,\n",
       " x2^2 - 14*x0 - 14*x1 + 2*x2 + 5]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x2^2 - 14*x0 - 14*x1 + 2*x2 + 5,\n",
       " x1*x2 + 8*x0 + 5*x1 + x2 - 13,\n",
       " x0*x2 + 13*x0 + 14*x1 + 12*x2 + 7,\n",
       " x1^2 + 5*x0 - 12*x1 + 8*x2 + 6,\n",
       " x0*x1 + 9*x0 + 8*x1 + 6*x2 - 12,\n",
       " x0^2 + 11*x0 - 12*x1 - 11*x2 + 13]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BB`: The border basis in the original dataset\n",
    "\n",
    "`G` : The computed border basis by improved border basis algorithm\n",
    "\n",
    "- Two bases are different (probably because of some sorting). \n",
    "- But they generate the same ideals, so it's fine. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal(G) == ideal(BB)\n",
    "# ideal(G) == ideal(F)  # also good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, x2, x1, x0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order ideal and border basis contains terms upto degree 3. However, `L` and `V` contains very high degree terms -- is that reasonable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x2^4,\n",
       " x1^2*x2^3,\n",
       " x0^2*x2^3,\n",
       " x1^3*x2^2,\n",
       " x0*x1^2*x2^2,\n",
       " x0^2*x1*x2^2,\n",
       " x0^2*x1^2*x2,\n",
       " x0^3*x1*x2,\n",
       " x0^4*x2,\n",
       " x0*x1^4,\n",
       " x0^2*x1^3,\n",
       " x0^4*x1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.border_basis_lib.utils import is_order_ideal\n",
    "\n",
    "is_order_ideal(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x0^3*x1^2,\n",
       " x0^2*x1^2*x2^2,\n",
       " x0^3*x1*x2^2,\n",
       " x0^4*x2^2,\n",
       " x1^5*x2,\n",
       " x0*x1^4*x2,\n",
       " x0^2*x1^3*x2,\n",
       " x0^5*x2,\n",
       " x1^6,\n",
       " x0*x1^5,\n",
       " x0^5*x1,\n",
       " x0^6,\n",
       " x0*x2^6,\n",
       " x1^2*x2^5,\n",
       " x0*x1*x2^5,\n",
       " x0^2*x2^5,\n",
       " x1^3*x2^4,\n",
       " x0*x1^2*x2^4,\n",
       " x0^2*x1*x2^4,\n",
       " x0^3*x2^4,\n",
       " x1^4*x2^3,\n",
       " x0*x1^3*x2^3]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, V, S = calculator.datasets[3][0]\n",
    "L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
